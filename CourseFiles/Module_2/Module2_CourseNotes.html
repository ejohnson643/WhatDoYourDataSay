
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Module 2: Parameter Estimation and Model Fitting &#8212; What Do Your Data Say?</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Worksheet 2.1: An introdution to bootstrapping" href="Worksheet_2_1_Bootstrapping.html" />
    <link rel="prev" title="Module 2" href="Module_2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/PCA_Animation_WDYDS.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">What Do Your Data Say?</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    What Do Your Data Say?
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Resources.html">
   Course Resources
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../AboutUs.html">
     About Us
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../CurriculumAlignmentTables.html">
     Curriculum Alignment Tables
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Rubric.html">
     Rubric
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../HowTo_AssignmentAttempt.html">
     How-To: Make an Assignment Attempt
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../HowTo_AssignmentCompletion.html">
     How-To: Complete Assignments
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../HowTo_SelfAssessment.html">
     How-To: Self-Assessment
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../Modules.html">
   Modules
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../Module_0/Module_0.html">
     Module 0: Python Tutorial
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Module_1/Module_1.html">
     Module 1: The Basics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Module1_CourseNotes.html">
       Module 1: The Basics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Worksheet_1_1_CoinFlipping.html">
       Worksheet 1.1: Coin Tossing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Worksheet_1_1_CoinFlipping_Solutions.html">
       SOLUTIONS to Worksheet 1.1: Coin Tossing
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Worksheet_1_2_SquareRootN.html">
       Worksheet 1.2: The Spread in Distributions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Worksheet_1_2_SquareRootN_Guide.html">
       GUIDE to Worksheet 1.2: The Spread in Distributions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Worksheet_1_3_EffectOfPriors.html">
       Worksheet 1.3: Bayes’ Theorem and the Effect of Priors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Worksheet_1_3_EffectOfPriors_Guide.html">
       GUIDE to Worksheet 1.3: Bayes’ Theorem and the Effect of Priors
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Assignment_1.html">
       Assignment 1
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Module_1/Assignment1_Hints.html">
       Assignment 1: Hints and guidance
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="Module_2.html">
     Module 2
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Module 2: Parameter Estimation and Model Fitting
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Worksheet_2_1_Bootstrapping.html">
       Worksheet 2.1: An introdution to bootstrapping
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Worksheet_2_1_Bootstrapping_Solutions.html">
       SOLUTIONS to Worksheet 2.1: Bootstrapping
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Worksheet_2_2_OLS_LinReg.html">
       Worksheet 2.2: OLS Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Worksheet_2_2_OLS_LinReg_Solutions.html">
       SOLUTIONS to Worksheet 2.2: OLS Linear Regression
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Assignment_2.html">
       Assignment 2
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Assignment2_Hints.html">
       Assignment 2: Hints and Guidance
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Module_3/Module_3.html">
     Module 3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Module_4/Module_4.html">
     Module 4
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../markdown-notebooks.html">
   Notebooks with MyST Markdown
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../notebooks.html">
   Content with notebooks
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ejohnson643/WhatDoYourDataSay"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ejohnson643/WhatDoYourDataSay/issues/new?title=Issue%20on%20page%20%2FCourseFiles/Module_2/Module2_CourseNotes.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/CourseFiles/Module_2/Module2_CourseNotes.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-atom-of-parameter-estimation">
   The atom of parameter estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-estimation">
     Parameter estimation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-likelihood-and-maximum-a-posteriori-estimates">
   Maximum likelihood and maximum A Posteriori estimates
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-likelihood-estimation">
     Maximum Likelihood Estimation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-estimating-the-standard-deviation-of-a-normal-random-variable">
       Example: estimating the standard deviation of a normal random variable
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">
     Maximum
     <em>
      a posteriori
     </em>
     estimation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#intervals-of-confidence">
   Intervals of confidence
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confidence-intervals">
     Confidence intervals
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#credible-intervals">
     Credible intervals
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrapping">
     Bootstrapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-atom-of-model-fitting-least-squares-regression">
   The atom of model fitting: least-squares regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ordinary-least-squares-regression">
     Ordinary least-squares regression
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-likelihood-formulation">
       Maximum-likelihood formulation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#residual-distributions">
       Residual Distributions
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-a-posteriori-formulation">
       Maximum
       <em>
        a posteriori
       </em>
       formulation
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Module 2: Parameter Estimation and Model Fitting</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-atom-of-parameter-estimation">
   The atom of parameter estimation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameter-estimation">
     Parameter estimation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maximum-likelihood-and-maximum-a-posteriori-estimates">
   Maximum likelihood and maximum A Posteriori estimates
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-likelihood-estimation">
     Maximum Likelihood Estimation
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#example-estimating-the-standard-deviation-of-a-normal-random-variable">
       Example: estimating the standard deviation of a normal random variable
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#maximum-a-posteriori-estimation">
     Maximum
     <em>
      a posteriori
     </em>
     estimation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#intervals-of-confidence">
   Intervals of confidence
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#confidence-intervals">
     Confidence intervals
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#credible-intervals">
     Credible intervals
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bootstrapping">
     Bootstrapping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-atom-of-model-fitting-least-squares-regression">
   The atom of model fitting: least-squares regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ordinary-least-squares-regression">
     Ordinary least-squares regression
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-likelihood-formulation">
       Maximum-likelihood formulation
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#residual-distributions">
       Residual Distributions
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-a-posteriori-formulation">
       Maximum
       <em>
        a posteriori
       </em>
       formulation
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="module-2-parameter-estimation-and-model-fitting">
<h1>Module 2: Parameter Estimation and Model Fitting<a class="headerlink" href="#module-2-parameter-estimation-and-model-fitting" title="Permalink to this headline">#</a></h1>
<p>In <a class="reference internal" href="../Module_1/Module_1.html"><span class="doc std std-doc">the previous chapter</span></a> we introduced the basics of probability and hopefully convinced you that a probabilistic view of the world might be a useful framework in which to perform experiments and analyses.  However, the critical reader may have noted that we didn’t really gain much in the way of tools that let us <em>learn new things</em>.  We covered probability distributions and the Central Limit Theorem (CLT), but you would be justified in feeling that you don’t know how to use this new information practically.  In this chapter, we will introduce the first two tools that a quantitative researcher should employ when attacking a data set:</p>
<ul class="simple">
<li><p>Estimating model parameters from data and creating bounds on where we expect the parameter to exist.</p></li>
<li><p>Least-squares regression for fitting (linear) models.</p></li>
</ul>
<p>Students who have seen the words “confidence intervals” and “linear regression” may be surprised that we’re spending time on these topics, but what we hope to show you is that these two tools are much more profound and useful than one might expect.  In particular, we will see how these methods will help us start to answer the question <em>“What do your data say?”</em></p>
<p>It’s also worth noting that these concepts form the basis of almost all advanced methods in statistics and machine learning, including dimensionality reduction, manifold learning, and clustering. The effort you put in to understand the basics of parameter estimation will help you use these tools more confidently and be more critical about when and how they are applied.</p>
<section id="the-atom-of-parameter-estimation">
<h2>The atom of parameter estimation<a class="headerlink" href="#the-atom-of-parameter-estimation" title="Permalink to this headline">#</a></h2>
<p>In this first section we’re going to discuss what it even means to “estimate a parameter”.  In the previous chapter, we learned how to calculate moments and percentiles, but we didn’t discuss how to answer the question “what number should I tell my neighbor that I measured?”  That is, if I have to report one value for some quantity, what value should I give?  This is called making a <em>point estimate</em> of this quantity.</p>
<div class="admonition-parameter-estimation-questions admonition">
<p class="admonition-title">Parameter estimation questions</p>
<p>Once we’ve gotten our point estimate, some natural questions are:</p>
<ul class="simple">
<li><p>How likely am I to observe this estimate?</p></li>
<li><p>How confident are you in this estimate?</p></li>
<li><p>How much deviation from this estimate should I expect if I re-did your experiment?</p></li>
</ul>
</div>
<p>These questions are innately tied to a probabilistic and distributional way of thinking and can be answered by looking at the <em>shapes</em> of specific distributions.  Specifically, we’ll show how to calculate classical <strong>confidence intervals</strong>, Bayesian <strong>credible intervals</strong>, and how to use <strong>bootstrapping</strong> to reconstruct how our quantity of interest is distributed. In particular, by the end of this module, you should see that bootstrapping is one of the most useful data analysis tools we have for attacking data of any kind!</p>
<section id="parameter-estimation">
<h3>Parameter estimation<a class="headerlink" href="#parameter-estimation" title="Permalink to this headline">#</a></h3>
<p>Before we can get to the exciting parts about intervals and curve-fitting, it is worth spending a moment being precise about what we are even talking about when we say “estimate this quantity.”  To explore this, consider a set of <span class="math notranslate nohighlight">\(N\)</span> independent and identically distributed (i.i.d.) random variables <span class="math notranslate nohighlight">\(x_i\)</span>.  Let’s say that we’re interested in the mean of these random variables, which we’ll call <span class="math notranslate nohighlight">\(\mu\)</span>. (For example, maybe we’re counting the number of heads in some coin flips, or the number of photons that hit a detector, or we want the mean time that a bacteria spins counter-clockwise.)</p>
<p>Let’s say that you’ve collected your data, the <span class="math notranslate nohighlight">\(x_i\)</span>, and then your collaborator comes by and asks for your estimate of the mean, let’s denote it <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>; what do you say?  You may be inclined to say that your estimate is simply the average (<span class="math notranslate nohighlight">\(\bar{x} = \frac{1}{N}\sum_{i=1}x_i\)</span>), so you pull out a calculator and tell your collaborator that <span class="math notranslate nohighlight">\(\hat{\mu} = \bar{x} = 10\)</span>.  This works great until a week later you realize that you forgot to enter some of the <span class="math notranslate nohighlight">\(x_i\)</span> into your calculator and actually <span class="math notranslate nohighlight">\(\bar{x} = 9\)</span>.  You run over to your collaborator who kindly re-runs their analysis with <span class="math notranslate nohighlight">\(\bar{x} = 9,\)</span> but you are left wondering what the <em>true</em> mean, <span class="math notranslate nohighlight">\(\mu\)</span>, of your random variables is.  That is, if you added a few more observations, how much would the mean change?  What if you repeated the experiment, what mean would you calculate then?  If you had infinite data, what would you calculate?</p>
<p>Concerned by this, you take some time and repeat your experiment to get a new set of <span class="math notranslate nohighlight">\(N\)</span> observations, <span class="math notranslate nohighlight">\(x_j\)</span>.  You calculate <span class="math notranslate nohighlight">\(\bar{x}\)</span> and get 12!  You’ve now seen <span class="math notranslate nohighlight">\(\bar{x} = 9, 10,\)</span> and 12, so which should you use for <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>?</p>
<p>To answer this question, consider that we can treat not only our data <span class="math notranslate nohighlight">\(x_i\)</span> to be random variables, but also our estimate for the mean, <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>, to be a random variable.  That is, we can try and describe our quantities, <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> via <em>probability distributions</em>, <span class="math notranslate nohighlight">\(P_x(X=x_i)\)</span> and <span class="math notranslate nohighlight">\(P_{\hat{\mu}(M = \hat{\mu})}\)</span>.  However, the problem arises in that while we might have many (<span class="math notranslate nohighlight">\(N\)</span>) data points, <span class="math notranslate nohighlight">\(x_i\)</span>, so that we can at least empirically describe <span class="math notranslate nohighlight">\(P_x\)</span>, we only have one value for <span class="math notranslate nohighlight">\(\hat{\mu}=\bar{x}\)</span>, so we can’t make a good description of <span class="math notranslate nohighlight">\(P_{\hat{\mu}}\)</span> empirically.  Of course, if we <em>could</em> pin down <span class="math notranslate nohighlight">\(P_{\hat{\mu}}\)</span>, theoretically or empirically, then all of the work in the previous section would help us immensely: we could calculate the expected value of <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> and we could start to talk about the spread in <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> that we might see.</p>
<div class="admonition-the-big-problem admonition">
<p class="admonition-title">The Big Problem</p>
<p>The problem of describing <span class="math notranslate nohighlight">\(P_{\hat{\mu}}\)</span> is what is called  the problem of <em>parameter estimation</em>.</p>
</div>
<p>Going forward, we are going to continue trying to estimate the mean, <span class="math notranslate nohighlight">\(\mu\)</span>, of a set of random variables, <span class="math notranslate nohighlight">\(x_i\)</span>, but it’s worth noting that this problem generalizes to <em>any parameter</em>, <span class="math notranslate nohighlight">\(\theta\)</span>, that might depend on our data.  That is, while we’re going to elaborate on some <em>specific</em> calculations for <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>, we’re also going to outline the <em>general</em> techniques for any parameter estimator <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>.</p>
</section>
</section>
<section id="maximum-likelihood-and-maximum-a-posteriori-estimates">
<h2>Maximum likelihood and maximum A Posteriori estimates<a class="headerlink" href="#maximum-likelihood-and-maximum-a-posteriori-estimates" title="Permalink to this headline">#</a></h2>
<p>Before we get too much further, it should be said that there is no “correct” answer to the problem of “how should I calculate <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>, an estimate of <span class="math notranslate nohighlight">\(\theta\)</span>?”  The <a class="reference external" href="https://en.wikipedia.org/wiki/Point_estimation">Wikipedia page</a> on point estimation lists <em>nine</em> different methods for answering this question, each of which uses its own assumptions and tools.  What we want to highlight and emphasize are two of the most widely-used and intuitive methods, <em>Maximum Likelihood Estimation</em> (ML Estimation or MLE) and <em>Maximum a Posteriori Estimation</em> (MAP Estimation).</p>
<section id="maximum-likelihood-estimation">
<h3>Maximum Likelihood Estimation<a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this headline">#</a></h3>
<p>The premise of ML estimation is simple: write down the <em>likelihood</em> function, <span class="math notranslate nohighlight">\(f(x_i|\theta)\)</span>, and say that <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is the value of the parameter <span class="math notranslate nohighlight">\(\theta\)</span> that <em>maximizes the likelihood</em>.  <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is known as the <em>maximum likelihood estimator</em> (MLE) for the parameter <span class="math notranslate nohighlight">\(\theta\)</span>.  In the case of a mean of i.i.d. random variables, thanks to the Central Limit Theorem (CLT) we know that <span class="math notranslate nohighlight">\(\mu\)</span> is distributed as a Gaussian distribution with mean <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma = \sigma_x/\sqrt{N}\)</span>, where <span class="math notranslate nohighlight">\(\sigma_x\)</span> is the standard deviation of <span class="math notranslate nohighlight">\(x_i\)</span>. If this isn’t clear, make sure to return to the previous set of notes for more details.  The important point here is that the CLT tells us that <em>sums</em> are distributed normally.</p>
<p>Then ML estimation says that what we want to do is consider the likelihood of observing our data <span class="math notranslate nohighlight">\(\bar{x}\)</span> given different values for <span class="math notranslate nohighlight">\(\mu\)</span> and maximize it.  The formula for a Gaussian distribution is</p>
<div class="math notranslate nohighlight" id="equation-eqn-defngaussdist">
<span class="eqno">(13)<a class="headerlink" href="#equation-eqn-defngaussdist" title="Permalink to this equation">#</a></span>\[P\left(z \left| \mu, \sigma^2\right.\right) =
    \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(
    -\frac{(z - \mu)^2}{2\sigma^2}
\right),\]</div>
<p>where <span class="math notranslate nohighlight">\(z\)</span> is the quantity that is distributed, <span class="math notranslate nohighlight">\(\mu\)</span> is the mean of <span class="math notranslate nohighlight">\(z\)</span>, and <span class="math notranslate nohighlight">\(\sigma^2\)</span> is the variance of <span class="math notranslate nohighlight">\(z\)</span>.\</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>In Python, create a variable for the mean and variance, <code class="docutils literal notranslate"><span class="pre">mu</span></code> = 2 and <code class="docutils literal notranslate"><span class="pre">sigmaSq</span></code> = 1.  Create a grid of <span class="math notranslate nohighlight">\(z\)</span>-values (maybe using <code class="docutils literal notranslate"><span class="pre">np.linspace</span></code>) and implement this formula to calculate the probability as a function of <span class="math notranslate nohighlight">\(z\)</span>.  Use <code class="docutils literal notranslate"><span class="pre">plt.scatter</span></code> to show the calculated probabilities versus the <span class="math notranslate nohighlight">\(z\)</span>-values and confirm that you see the expected “bell” curve!</p>
</div>
<p>In the present case, we are considering the distribution of the mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>, so we will substitute <span class="math notranslate nohighlight">\(\bar{x}\)</span> for <span class="math notranslate nohighlight">\(z\)</span> in this equation.  We then want to find the value of <span class="math notranslate nohighlight">\(\mu\)</span> that maximizes <span class="math notranslate nohighlight">\(P(\bar{x}|\mu, \sigma^2)\)</span>, which we write in symbols like this:</p>
<div class="math notranslate nohighlight" id="equation-eqn-llh-mean">
<span class="eqno">(14)<a class="headerlink" href="#equation-eqn-llh-mean" title="Permalink to this equation">#</a></span>\[\hat{\mu} = \max_{\mu}\left[
    \frac{1}{\sqrt{2\pi\sigma^2}}
    \exp\left(-\frac{(\bar{x} - \mu)^2}{2\sigma^2}\right)
\right]\]</div>
<p>This notation says that we should set <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> to be the value of <span class="math notranslate nohighlight">\(\mu\)</span> (as indicated by the <span class="math notranslate nohighlight">\(\mu\)</span> under the <span class="math notranslate nohighlight">\(\max\)</span>) that maximizes the quantity in the square brackets.  We can then take the logarithm of the stuff inside the brackets and drop the <span class="math notranslate nohighlight">\(1/\sqrt{2\pi\sigma^2}\)</span>, as this won’t change where the function is maximized.</p>
<div class="math notranslate nohighlight" id="equation-eqn-sumsqmax">
<span class="eqno">(15)<a class="headerlink" href="#equation-eqn-sumsqmax" title="Permalink to this equation">#</a></span>\[\hat{\mu} = \max_{\mu}\left[
    \log\left[
    \exp\left(-\frac{(\bar{x} - \mu)^2}{2\sigma^2}\right)
\right]\right] = \max_{\mu}\left[
    -\frac{(\bar{x} - \mu)^2}{2\sigma^2}
\right].\]</div>
<p>We can then quickly see that <span class="math notranslate nohighlight">\((\bar{x}-\mu)^2\)</span> is always positive, so this function is maximized when <span class="math notranslate nohighlight">\(\bar{x} = \mu\)</span> and we can write that the MLE is</p>
<div class="math notranslate nohighlight">
\[\hat{\mu} = \bar{x} = \frac{1}{N}\sum_{i=1}^Nx_i\]</div>
<p>because setting <span class="math notranslate nohighlight">\(\hat{\mu}\)</span> to this value <em>maximizes the likelihood</em> of observing the data <span class="math notranslate nohighlight">\(x_i\)</span>.</p>
<p>If the math here is giving you difficulties, don’t worry; it’s here for the sake of being thorough, not because it’s essential to doing parameter  estimation.  The thing you should take away is that <em>one way</em> of making estimates is to maximize a likelihood function.  Also, as the “Try It Yourself” boxes will try to point out, if you don’t understand a formula or equation on paper, you can always try and <em>see</em> it in your computer with Python.</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>Again using <code class="docutils literal notranslate"><span class="pre">mu</span></code> = 2 and <code class="docutils literal notranslate"><span class="pre">sigmaSq</span></code> = 1, plot the quantity from Equation <a class="reference internal" href="#equation-eqn-sumsqmax">(15)</a> <span class="math notranslate nohighlight">\(\hat{\mu} = -\frac{(z - \mu)^2}{2\sigma^2}\)</span> versus <span class="math notranslate nohighlight">\(z\)</span> alongside your bell curve from above.  Where is this quantity maximized?  Is it at the same place as the Gaussian distribution?  Does changing <span class="math notranslate nohighlight">\(\sigma^2\)</span> affect anything?</p>
</div>
<p>In general, given some <em>model</em> connecting <span class="math notranslate nohighlight">\(x_i\)</span> and your parameter <span class="math notranslate nohighlight">\(\theta\)</span>, which we’ll call <span class="math notranslate nohighlight">\(f(x_i|\theta)\)</span>, then we can make an MLE, <span class="math notranslate nohighlight">\(\hat{\theta},\)</span> by maximizing this function over <span class="math notranslate nohighlight">\(\theta\)</span>.  In this case, it turns out that our gut call of using <span class="math notranslate nohighlight">\(\hat{\mu} = \bar{x}\)</span> was equivalent to using the maximum-likelihood estimator; this will not always be the case!</p>
<p>We’ll continue to make MLEs later, but for now we’ll summarize the idea as so:</p>
<div class="admonition-maximum-likelihood-estimation admonition">
<p class="admonition-title">Maximum Likelihood Estimation</p>
<p>Using a <em>likelihood</em> function <span class="math notranslate nohighlight">\(f(\vec{x*|\theta)\)</span>, the <strong>Maximum Likelihood Estimator</strong> (MLE) <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is defined as <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \max_{\theta}\left[
    f\left(\vec{x}|\theta\right)
\right]\]</div>
</div>
<p>We’ll show in a moment that we can also make an MLE for the <em>variance</em>, <span class="math notranslate nohighlight">\(\sigma^2\)</span>, of the distribution of the mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span>.  If you’re uncomfortable with calculus, please feel free to skip over the following example to the formula at the end.  What you should take away from this example and the one above is that ML estimation is often an exercise in <em>algebraic manipulation</em>: you take your likelihood and find where it is maximized.  Once you have the formula, you’re good to go.  However, we caution that if you <em>can’t</em> follow or assess the derivation, then you should be skeptical that you understand the formula well enough to use it on its own, and you should bolster your conclusions by making the estimate in a different way as well.</p>
<section id="example-estimating-the-standard-deviation-of-a-normal-random-variable">
<h4>Example: estimating the standard deviation of a normal random variable<a class="headerlink" href="#example-estimating-the-standard-deviation-of-a-normal-random-variable" title="Permalink to this headline">#</a></h4>
<p>First, for this estimate, we’re going to start by <em>assuming</em> that our data, <span class="math notranslate nohighlight">\(x_i\)</span>, are distributed normally, with mean, <span class="math notranslate nohighlight">\(\mu\)</span>, and standard deviation <span class="math notranslate nohighlight">\(\sigma_x\)</span>.  Then the likelihood of observing a specific point, <span class="math notranslate nohighlight">\(x_i\)</span>, is given by subsituting <span class="math notranslate nohighlight">\(x_i=z\)</span> into Equation <a class="reference internal" href="#equation-eqn-defngaussdist">(13)</a>. We furthermore assume all of our observations are independent so that the likelihood of all the points is the <em>product</em> of their individual likelihoods.  That is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
    P\left(
        x_1, x_2, x_3, \ldots \left| \mu, \sigma_x^2
    \right.\right) &amp;= 
    \prod_{i=1}^N \frac{1}{\sqrt{2\pi\sigma_x^2}}
    \exp\left(
        -\frac{(x_i - \mu)^2}{2\sigma_x^2}
    \right)\\
    &amp;= \left(
        \frac{1}{2\pi\sigma_x^2}
    \right)^{N/2} \exp\left(
        -\frac{1}{2\sigma_x^2}\sum_{i=1}^N (x_i-\mu)^2
    \right),
\end{align}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\prod\)</span> is the notation for a  <em>product</em> of terms that increment <span class="math notranslate nohighlight">\(i\)</span> from 1 to N and the product of exponentials sum in the exponent.</p>
<p>We want to find the value of <span class="math notranslate nohighlight">\(\sigma_x\)</span> that maximizes this function, so we’re going to use a bit of calculus to do so (this problem isn’t as obvious as finding the estimate for <span class="math notranslate nohighlight">\(\mu\)</span>).  First, however, we’ll again use the fact that maximizing the <em>logarithm</em> of the likelihood (often called the <em>log-likelihood</em>) is the same as maximizing the likelihood itself.  This lets us write</p>
<div class="math notranslate nohighlight">
\[\log\left[P\left(
    x_1, x_2, x_3, \ldots \left| \mu, \sigma_x^2
\right.\right)\right] = 
-\frac{N}{2}\log\left[
    2\pi\sigma_x^2
\right] - \frac{1}{2\sigma_x^2}
\sum_{i=1}^N(x_i-\mu)^2\]</div>
<p>Taking the derivative with respect to <span class="math notranslate nohighlight">\(\sigma\)</span> and setting it equal to zero lets us find the maxima of this quantity so that we can write</p>
<div class="math notranslate nohighlight" id="equation-eqn-stddevmle">
<span class="eqno">(16)<a class="headerlink" href="#equation-eqn-stddevmle" title="Permalink to this equation">#</a></span>\[0 = -\frac{N}{\sigma} + \frac{1}{\sigma^3}\sum_{i=1}^N(x_i - \mu)^2 \qquad \Rightarrow \qquad \sigma_x^2 = \frac{1}{N}\sum_{i=1}^N(x_i - \mu)^2.\]</div>
<p>Now, we’re not quite done yet!  This is an estimate for the standard deviation of the <em>data</em>.  We said that we wanted an estimate for the standard deviation of the <em>mean of the data</em> (since it’s a random variable).  However, if you try to do what we just did with the likelihood of the mean in Equation <a class="reference internal" href="#equation-eqn-llh-mean">(14)</a>, you will encounter</p>
<div class="math notranslate nohighlight">
\[\hat{\sigma}^2 = (\bar{x} - \mu)^2,\]</div>
<p>but if we don’t know <span class="math notranslate nohighlight">\(\mu\)</span> (which we often don’t!), then using our best guess that <span class="math notranslate nohighlight">\(\hat{\mu} = \bar{x}\)</span> tells us that <span class="math notranslate nohighlight">\(\hat{\sigma}^2 = 0\)</span>!  This is obviously incorrect, so to get even somewhere close to an answer, we had to assume that the data were normally-distributed.</p>
<p>So now we’ve found that our best estimate for the standard deviation of normally-distributed random variables is given in Equation <a class="reference internal" href="#equation-eqn-stddevmle">(16)</a>. Note this formula takes the form we’d expect: it’s the definition of how we were taught to calculate the standard deviation!  (Of course, this is a <a class="reference external" href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">biased estimator</a> of the standard deviation, but we’ll leave that discussion to other resources.)  To get an estimate for the standard deviation of the <em>mean</em>, we’ll invoke the CLT, which tells us that the mean’s variance is <span class="math notranslate nohighlight">\(\sigma_x^2/N\)</span> so that we can use</p>
<div class="math notranslate nohighlight" id="equation-eqn-mle-mean-sigma">
<span class="eqno">(17)<a class="headerlink" href="#equation-eqn-mle-mean-sigma" title="Permalink to this equation">#</a></span>\[\hat{\sigma} = \frac{\hat{\sigma}_x}{\sqrt{N}} = \frac{1}{N}\sqrt{\sum_{i=1}^N(x_i-\hat{x})^2}\]</div>
<p>as our estimate.</p>
<p>Again, the point of this example was not to prove that we can do math but to demonstrate what ML Estimation looks like in practice.  There’s nothing particularly profound about it, but the formulas you learn are sometimes more constrained by algebra than whether they are really what you want to estimate.  That is: <strong>You can sometimes maximize the likelihood function to estimate parameters.</strong></p>
<p>Of course, if we’re not concerned with doing any algebraic analysis of the MLE, then we can always use computational techniques to find the maximum of our likelihood function.  In the examples shown in these notes, where we only have a few parameters, this is probably doable, but in more complicated scenarios can be quite difficult.  In this way, while ML estimation is a hugely successful methodology for estimating parameters, as you saw above and will see in the assignments, actually determining closed form answers for an estimator sometimes be tricky.  In particular, for those not fluent in probability notation and calculus, bringing the simple premise of “maximize this function” to life can be quite difficult!  As a result, statistics textbooks become complex lists of recipes, because it takes so much work to derive the results that it can’t be asked of the average user.</p>
<p>Thankfully, as we noted, there are alternative approaches that are sometimes more effective or practical.  In the next section we’ll introduce <strong>Maximum <em>a Posteriori</em> Estimation</strong> (MAP Estimation), which still relies on mathematical theory to work, but in a more flexible manner, and later we’ll introduce the computational technique of <strong>bootstrapping</strong>.</p>
</section>
</section>
<section id="maximum-a-posteriori-estimation">
<h3>Maximum <em>a posteriori</em> estimation<a class="headerlink" href="#maximum-a-posteriori-estimation" title="Permalink to this headline">#</a></h3>
<p>MAP estimation is a method for generating point estimates in a manner similar to MLE except that instead of maximizing the likelihood function, we find the maximum of the <em>posterior</em> distribution for our parameter (hence the name maximum <em>a posteriori</em>).  Consider <a class="reference internal" href="#fig-bayesmapest"><span class="std std-numref">Fig. 16</span></a>, where the Bayesian posterior generation process for the mean of some data has been illustrated.</p>
<p>In this Figure, we’ve posed two priors: a uniform prior for the mean, <span class="math notranslate nohighlight">\(\mu\)</span>, from -1 to 1 and a Gaussian prior with a shifted mean and widened variance.</p>
<div class="math notranslate nohighlight">
\[P(\mu) = \mathcal{U}(-1, 1)
\qquad\qquad\text{and}\qquad\qquad
P(\mu) = \mathcal{N}\left(
    \bar{x}-0.4,
    1.5\times\sqrt{\frac{Var[x]}{N}}
\right)\]</div>
<p>If we use the MLE for the standard deviation, the likelihood function for the mean is the same as in Equation <a class="reference internal" href="#equation-eqn-llh-mean">(14)</a>:</p>
<div class="math notranslate nohighlight">
\[P\left(
    \bar{x}\left|\mu, \sigma = \sqrt{\frac{Var[x]}{N}}\right.
\right) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left[
    -\frac{(\bar{x}-\mu)^2}{2\sigma^2}
\right]\]</div>
<p>We can then multiply these distributions to get the posterior computationally.</p>
<figure class="align-default" id="fig-bayesmapest">
<img alt="Illustration of the MAP estimation of the mean of $N=100$ normally distributed random variables under two different priors.  All three panels show the location of the MLE ($\hat{\mu} = \bar{x} = -0.104$) and the true population mean, $\mu_{TRUE} = 0.$  The left panel shows two different prior distributions for the sample mean, $\mu$.  The center panel shows the likelihood function for the data ($\sigma$ was set to be $\sqrt{\text{Var}[x]/N}$).  The right panel shows the two posteriors and their MAP estimates." src="../../_images/Bayes_MAP_Estimates_Chapter2_Example.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Illustration of the MAP estimation of the mean of <span class="math notranslate nohighlight">\(N=100\)</span> normally distributed random variables under two different priors.  All three panels show the location of the MLE (<span class="math notranslate nohighlight">\(\hat{\mu} = \bar{x} = -0.104\)</span>) and the true population mean, <span class="math notranslate nohighlight">\(\mu_{TRUE} = 0.\)</span>  The left panel shows two different prior distributions for the sample mean, <span class="math notranslate nohighlight">\(\mu\)</span>.  The center panel shows the likelihood function for the data (<span class="math notranslate nohighlight">\(\sigma\)</span> was set to be <span class="math notranslate nohighlight">\(\sqrt{\text{Var}[x]/N}\)</span>).  The right panel shows the two posteriors and their MAP estimates.</span><a class="headerlink" href="#fig-bayesmapest" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<!-- \begin{figure*[htbp]
    \centering
    \captionsetup{width=0.8\linewidth*
    \includegraphics[width=\linewidth]{Bayes_MAP_Estimates_Chapter2_Example.pdf*
    \caption{Illustration of the MAP estimation of the mean of $N=100$ normally distributed random variables under two different priors.  All three panels show the location of the MLE ($\hat{\mu} = \bar{x* = -0.104$) and the true population mean, $\mu_{TRUE* = 0.$  The left panel shows two different prior distributions for the sample mean, $\mu$.  The center panel shows the likelihood function for the data ($\sigma$ was set to be $\sqrt{\text{Var*[x]/N*$).  The right panel shows the two posteriors and their MAP estimates.*
    \label{fig:BayesMAPEst*
\end{figure* -->
<p>Thanks to the modern computer, making both ML and MAP estimates can be as simple as finding the maximum value of a curve.  What is nice then about using a Bayesian framework here is that we are explicitly incorporating any priors that we want and we don’t need to do too much theoretical work.  Moreover, we bring up the Bayesian method because it more naturally facilitates talking about the whole distribution instead of a single point estimate.  In fact, because the point of a Bayesian analysis is to end up with a distributional description, researchers often use the posterior expected value or <em>posterior median</em> as their point estimate.  The posterior median is often preferred since it is less sensitive to outliers or bad priors, as can be seen in <a class="reference internal" href="#fig-bayesmapest2"><span class="std std-numref">Fig. 17</span></a>, where a bad prior caused the posterior to be multi-modal (have multiple peaks).</p>
<p>We also bring up the Bayesian approach because it makes clear some of the implicit assumptions that often accompany an MLE.  For example, the likelihood function and a uniform prior gives a posterior that is identical to the likelihood, so that the MLE and MAP estimate will be the same.  This can clearly be seen in the blue lines in <a class="reference internal" href="#fig-bayesmapest"><span class="std std-numref">Fig. 16</span></a>, where the likelihood and posterior functions are both normal distributions that are centered on our MLE <span class="math notranslate nohighlight">\(\hat{\mu} = \bar{x}\)</span>.  In this way, the Bayesian approach is somewhat more flexible than the MLE approach in that we can loosen some assumptions on the parameters.</p>
<figure class="align-default" id="fig-bayesmapest2">
<img alt="Illustration of the MAP estimation of the mean of $N=100$ normally distributed random variables under two different priors as in {numref}`fig_BayesMAPEst`." src="../../_images/Bayes_MAP_Estimates_Chapter2_Example2.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Illustration of the MAP estimation of the mean of <span class="math notranslate nohighlight">\(N=100\)</span> normally distributed random variables under two different priors as in <a class="reference internal" href="#fig-bayesmapest"><span class="std std-numref">Fig. 16</span></a>.</span><a class="headerlink" href="#fig-bayesmapest2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<!-- \begin{figure*[htbp]
    \centering
    \captionsetup{width=0.8\linewidth*
    \includegraphics[width=\linewidth]{Bayes_MAP_Estimates_Chapter2_Example2.pdf*
    \caption{Illustration of the MAP estimation of the mean of $N=100$ normally distributed random variables under two different priors as in Figure \ref{fig:BayesMAPEst*.*
    \label{fig:BayesMAPEst2*
\end{figure* -->
<p>In any case, hopefully you now have some idea of the choices we can make when giving our collaborator just one number to describe parameters.  When we have some theory about how a parameter is distributed, we can try to make an MLE.  If we have a prior model for the parameter and a likelihood model for the data, then we can make posterior-based estimates.</p>
<div class="admonition-map-estimates admonition">
<p class="admonition-title">MAP estimates</p>
<p>MAP estimation is similar to ML estimation in that it is dependent on some theory in order to work.  However, incorporating priors can allow for greater flexibility in assumptions.</p>
</div>
<p>For a more detailed example of how to make a MAP estimate of quantities derived from exponentially distributed data (for example, from the time intervals from <a class="reference external" href="https://github.com/ejohnson643/WhatDoYourDataSay/blob/main/CourseFiles/Module_2/Resources/omega.txt">the bacterial chemotaxis data</a>), look to the end of the notes.  You will use the code and results of that example in <a class="reference internal" href="Assignment_2.html"><span class="doc std std-doc">Assignment 2</span></a>!</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>Use your Assignment 1 solutions or those provided to generate a MAP estimate of the switching rate <span class="math notranslate nohighlight">\(\lambda^+\)</span> or <span class="math notranslate nohighlight">\(\lambda^-\)</span> by maximizing the posterior distributions <em>computationally</em>.  That is, implement a solution and find the value of <span class="math notranslate nohighlight">\(\lambda\)</span> at which the posterior is maximized.  Compare this value to the posterior mean, median, and the MLE.</p>
</div>
</section>
</section>
<section id="intervals-of-confidence">
<h2>Intervals of confidence<a class="headerlink" href="#intervals-of-confidence" title="Permalink to this headline">#</a></h2>
<p>If you’re following closely, you may have noted that the previous section, while elaborating on topics from the first chapter, still didn’t answer all of our questions:</p>
<ul class="simple">
<li><p>How likely am I to observe this estimate?</p></li>
<li><p>How confident are you in this estimate?</p></li>
<li><p>How much deviation from this estimate should I expect?</p></li>
</ul>
<p>This is intentional; it helps to ground yourself more specifically in the problem at hand before we introduce the nebulous quantity of <em>confidence</em>.  Recall your earlier experiments with <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_j\)</span> and how you measured <span class="math notranslate nohighlight">\(\bar{x}\)</span> to be 9, 10, and 12, depending on which data was included in the calculation.  We also discussed how depending on what type of estimator you decide to calculate, you might report different numbers.  So the path forward might still seem a bit murky.</p>
<p>One potential solution is to model the sample distribution for the parameter (say, <span class="math notranslate nohighlight">\(\hat{\mu}\)</span>) and report that the MLE = <span class="math notranslate nohighlight">\(\bar{x}= 10\)</span> has a likelihood of 0.12, so that we can answer our first question.  But turning to the second, that answer might be concerning: 88% of the time it is not that number!  How can that be our report?  How can we have confidence in something that only happens 12% of the time?</p>
<p>The answer, as you have probably started to pick up on, is to use the probabilistic and distributional nature of these quantities to look not just at single points, but also to look at probabilities of whole <em>regions</em> of parameter space.  That is, rather than saying “<span class="math notranslate nohighlight">\(\hat{\mu} = 10\)</span>”, we’d like to say things like, “I expect <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> to be in this interval 82% of the time” or “60% of new experiments will deviate from <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> by 2 or less.”  In particular, this section will work on the development of specific types of intervals: <em>confidence intervals</em>, <em>credible intervals</em>, and finally, the use of <em>bootstrapping</em> to generate confidence intervals.</p>
<p>Before we get too much further, it’s also worth commenting on what we mean by <em>confidence</em>.  Intuitively, it is useful to think about the phrase “I have [<em>insert percentage</em>]% confidence in this parameter having these values,” so that “confidence” becomes synonymous with “probability of observation.”  This is a useful intuition as it lets us quantify a desirable outcome of our analysis.  However, as we’ll explain, the exact way that statement this will manifest itself will depend on how we decide to construct our intervals.</p>
<section id="confidence-intervals">
<h3>Confidence intervals<a class="headerlink" href="#confidence-intervals" title="Permalink to this headline">#</a></h3>
<p>First, and most briefly, we need to discuss confidence intervals.  Most directly, confidence intervals describe a region into which the true parameter value falls into <span class="math notranslate nohighlight">\(1-\alpha\%\)</span> of the time.  (<span class="math notranslate nohighlight">\(\alpha\)</span> is known as the <em>confidence level</em>) This is a precise and somewhat confusing statement, so it bears rephrasing: if you were to perform an experiment 100 times and measure the parameter estimate, <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>, and the 80% confidence interval of each of those experiments, then we would expect 80 of those confidence intervals to contain the true population parameter, <span class="math notranslate nohighlight">\(\theta\)</span>.  This <a class="reference external" href="https://rpsychologist.com/d3/CI/">website</a> provides an excellent visualization of how this works.</p>
<p>These comments are necessary before getting into the <em>how we calculate</em> confidence intervals because this is a non-obvious part of these tools.  Confidence intervals represent the range I would need to report to cover myself from being disagreed with in <span class="math notranslate nohighlight">\(1-\alpha\)</span>% of future experiments.  This is a very different quantity than the confidence we’ll be assessing with credible intervals.</p>
<p>OK, now for the <em>how</em> of confidence intervals.  Typically, as with ML estimation, one has to know something about how the parameter of interest is distributed, then intervals can be worked out based on that parameterization.  For example, the sample mean, <span class="math notranslate nohighlight">\(\bar{x}\)</span> is distributed normally, so we can say that it has a confidence interval given by</p>
<div class="math notranslate nohighlight" id="equation-eqn-stderror">
<span class="eqno">(18)<a class="headerlink" href="#equation-eqn-stderror" title="Permalink to this equation">#</a></span>\[\left[
    \bar{x}\pm z_{\alpha/2}\frac{s}{\sqrt{N}}
\right],\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\alpha/2}\)</span> is the <span class="math notranslate nohighlight">\(\alpha/2^{\text{th}}\)</span> percentile of the standard normal (<span class="math notranslate nohighlight">\(z\)</span>) distribution, and <span class="math notranslate nohighlight">\(s\)</span> is the sample standard deviation <span class="math notranslate nohighlight">\(\frac{1}{N-1}\sum_{i=1}^N\left(x_i-\bar{x}\right)^2\)</span>.  This is because this is the region in which <span class="math notranslate nohighlight">\(\alpha\)</span>% of the probability of a normal distribution lies.</p>
<p>That is, in general, we calculate confidence intervals by determining upper and lower bounds for a region such that some fraction of a distribution’s probability falls in that region.  The amount of probability that we want in the region is called the <em>confidence level</em>, and is typically indicated with <span class="math notranslate nohighlight">\(1-\alpha\)</span>.  Common values for <span class="math notranslate nohighlight">\(\alpha\)</span> are 0.1, 0.05, or 0.01 (90%, 95%, or 99%), depending on the field of research and type of data.\</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>Use this formula to add on to the work you did in <a class="reference internal" href="../Module_1/Worksheet_1_2_SquareRootN.html"><span class="doc std std-doc">Worksheet 1.2</span></a>.  Specifically, how does the confidence interval change as you change <span class="math notranslate nohighlight">\(N\)</span>, <span class="math notranslate nohighlight">\(M\)</span>, and <span class="math notranslate nohighlight">\(p\)</span>?</p>
</div>
<p>More formally, if we have a parameter, <span class="math notranslate nohighlight">\(\theta\)</span>, then we want to solve</p>
<div class="math notranslate nohighlight">
\[1-\alpha = P\left(L\leq \theta \leq U\right) = \int_L^U P\left(\theta = t\right) dt\]</div>
<p>for <span class="math notranslate nohighlight">\(L\)</span> and <span class="math notranslate nohighlight">\(U\)</span>, our lower and upper bounds.  Equation <a class="reference internal" href="#equation-eqn-stderror">(18)</a> is the result of solving this for the case when <span class="math notranslate nohighlight">\(\theta = \mu\)</span>, the mean of a set of random variables, so that <span class="math notranslate nohighlight">\(P(\theta)\)</span> is a normal distribution.  But for other parameters that are distributed differently, like a Poisson rate parameter or a regression coefficient, we’ll need to solve this  anew.  It often works to approximate the confidence interval with <a class="reference internal" href="#equation-eqn-stderror">(18)</a>, which is likely why it seems intuitive to use <code class="docutils literal notranslate"><span class="pre">mean</span></code><span class="math notranslate nohighlight">\(\pm\)</span><code class="docutils literal notranslate"><span class="pre">standard</span> <span class="pre">deviation</span></code> as a confidence interval of sorts, but it doesn’t work frequently or generally enough to be our only tool.  At the end of these notes we’ll delve into the derivation of the confidence interval for an exponentially rate parameter that you will make use of in the assignment.</p>
<p>Indeed, it is precisely because of this specificity that we move on to other methods.  It is not to say that knowing about confidence intervals is not useful, just that keeping a list of theoretical derivations is not generically useful enough to be the only weapon in your arsenal.</p>
</section>
<section id="credible-intervals">
<h3>Credible intervals<a class="headerlink" href="#credible-intervals" title="Permalink to this headline">#</a></h3>
<p>An alternative approach is the Bayesian <em>credible interval</em>, which is an interval of “confidence” that we can generate from a posterior distribution.  Specifically, if we have a posterior distribution for how our parameter of interest, <span class="math notranslate nohighlight">\(\theta\)</span>, is distributed, then we can use the usual interpretation of a probability distribution to find bounds around <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>, our estimate, the enclose <span class="math notranslate nohighlight">\(1-\alpha\)</span>% of the probability (mass) of <span class="math notranslate nohighlight">\(\theta\)</span> occurring.   That is, rather than worrying about exactly how <span class="math notranslate nohighlight">\(\theta\)</span> is distributed theoretically, we can consider our posterior and find a region that contains 95% of the probability (if <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>).</p>
<p>To do this, we have a few options, but we’ll only discuss the easiest: calculate the CDF and find the <span class="math notranslate nohighlight">\(\alpha/2^{\text{th}}\)</span> and <span class="math notranslate nohighlight">\((1-\alpha/2)^{\text{th}}\)</span> percentiles.<br />
The interval between these two points  is a region in which <span class="math notranslate nohighlight">\(\theta\)</span> has a likelihood of <span class="math notranslate nohighlight">\((1-\alpha)\)</span>% of existing.</p>
<p>Note that the use of this interval is slightly different than that of a confidence interval in that we are directly considering <span class="math notranslate nohighlight">\(\theta\)</span> to be a random variable and we are discussing the probability of <span class="math notranslate nohighlight">\(\theta\)</span> existing in a certain region.  Confidence intervals estimated our ability to know the true value of <span class="math notranslate nohighlight">\(\theta\)</span>, which is not a random variable, and therefore are useful in the context of setting expectations for further experimentation.  The credible interval describes our confidence <em>right now</em> about where <span class="math notranslate nohighlight">\(theta\)</span> lies.</p>
<p>Again, when we use a uniform prior on our parameter <span class="math notranslate nohighlight">\(\theta\)</span>, then the credible interval should coincide with the confidence interval.  The main benefit then of using a Bayesian approach is basically that if we’re going to be computationally generating the confidence interval anyways, then we might as well explicitly indicate what prior beliefs we have.  Always assuming that the parameter is uniform is clearly not a robust or safe assessment!</p>
<p>Finally, we note that while taking the interval given by the <span class="math notranslate nohighlight">\(\alpha/2^{\text{th}}\)</span> and <span class="math notranslate nohighlight">\((1-\alpha/2)^{\text{th}}\)</span> percentiles gives an interval with the correct amount of probability, it is not the <em>only</em> interval that gives this amount of probability.  For example, at a confidence level of 90%, we could have chosen the <span class="math notranslate nohighlight">\(1^{\text{st}}\)</span> and <span class="math notranslate nohighlight">\(91^{\text{st}}\)</span> percentiles, or the <span class="math notranslate nohighlight">\(7^{\text{th}}\)</span> and <span class="math notranslate nohighlight">\(97^{\text{th}}\)</span>.  Given this, it is sometimes recommended to find the interval containing <span class="math notranslate nohighlight">\(1-\alpha\)</span>% probability that is the <em>smallest</em>.  This is called a <em>highest density region</em> or HDR.  For most unimodal (only one peak) posteriors the HDR is very similar to the difference between the <span class="math notranslate nohighlight">\(\alpha/2^{\text{th}}\)</span> and <span class="math notranslate nohighlight">\((1-\alpha/2)^{\text{th}}\)</span> percentiles, but for multimodal distributions, the HDR might be more intuitive, as explained in this <a class="reference external" href="https://stats.stackexchange.com/questions/148439/what-is-a-highest-density-region-hdr">post</a>.</p>
<p>In any case, the technical differences between using an HDR or percentiles are secondary to the probabilistic interpretation of the credible interval as a region where I think <span class="math notranslate nohighlight">\(\theta\)</span> exists now.  Confidence intervals, which describe how well I think I can measure <span class="math notranslate nohighlight">\(\theta\)</span> in any given experiment, are a different beast.</p>
</section>
<section id="bootstrapping">
<h3>Bootstrapping<a class="headerlink" href="#bootstrapping" title="Permalink to this headline">#</a></h3>
<p>Given the difficulties with both of the previous methods (confidence intervals are theoretically difficult and credible intervals can be computationally difficult), you may be feeling a bit worried about how hard it is to answer “where is <span class="math notranslate nohighlight">\(\theta\)</span>!?”  Thankfully, the modern computer has given us the ability to use a computational technique known as <em>bootstrapping</em>.</p>
<p>As described somewhat comprehensively in 1986, <a class="reference external" href="https://projecteuclid.org/euclid.ss/1177013815">Tibshirani and Efron</a> showed that if we have some data, <span class="math notranslate nohighlight">\(x_i\)</span> and we want to estimate some parameter <span class="math notranslate nohighlight">\(\theta\)</span>.  We can <em>approximate</em> the true distribution of <span class="math notranslate nohighlight">\(\theta\)</span> by <em>resampling</em> our data <em>with replacement</em> and recalculating <span class="math notranslate nohighlight">\(\theta\)</span> on our resampled datasets.</p>
<p>That is, I take my data <span class="math notranslate nohighlight">\(x_1, x_2, \ldots, x_N\)</span> and I make a new data set of <span class="math notranslate nohighlight">\(N\)</span> points by randomly drawing data points from my collection <span class="math notranslate nohighlight">\(x_i\)</span>, where each random draw comes from the full set of <span class="math notranslate nohighlight">\(x_i\)</span>, so that my new data set may have multiple <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(x_{17*\)</span> (for example).  This is what is meant by <em>with replacement</em>; if we were drawing our cards from a deck, I would be <em>replacing</em> the cards I had drawn so the deck is always full.</p>
<p>Using this new data set, I calculate <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>.  Then I generate a new data set and do it again.  Then I do the process again many times.  Eventually I will have a <em>distribution</em> for <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> and it can be shown that this distribution will eventually (with  resampling) become equivalent to the sampling distribution that I was trying to describe with a confidence interval.  So instead of performing a bunch of theoretical calculations, I can instead look at the percentiles of the bootstrapped distribution for <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> to give my confidence interval, regardless of whether I know the exact way of writing down the distribution theoretically.</p>
<figure class="align-default" id="fig-exbootstddev">
<img alt="Bootstrapped distribution for the sample standard deviation ({eq}`eqn_unbiasedSigma`).  The original sample's estimate $\hat{s}$ is shown, as are the theoretical and bootstrapped confidence intervals.  Note that the theory here does not match well with the bootstrapping because the random variables $x_i$ were actually uniformly distributed, not normally distributed, which may have been hard to assess with only $N=10$ samples!" src="../../_images/Example_Bootstrapping_StdDev.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">Bootstrapped distribution for the sample standard deviation (<a class="reference internal" href="#equation-eqn-unbiasedsigma">(19)</a>).  The original sample’s estimate <span class="math notranslate nohighlight">\(\hat{s}\)</span> is shown, as are the theoretical and bootstrapped confidence intervals.  Note that the theory here does not match well with the bootstrapping because the random variables <span class="math notranslate nohighlight">\(x_i\)</span> were actually uniformly distributed, not normally distributed, which may have been hard to assess with only <span class="math notranslate nohighlight">\(N=10\)</span> samples!</span><a class="headerlink" href="#fig-exbootstddev" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<!-- \begin{figure*[htbp]
    \centering
    \includegraphics[width=\linewidth]{Example_Bootstrapping_StdDev.pdf*
    \caption{Bootstrapped distribution for the sample standard deviation (Equation \ref{eqn:unbiasedSigma*).  The original sample's estimate $\hat{s*$ is shown, as are the theoretical and bootstrapped confidence intervals.  Note that the theory here does not match well with the bootstrapping because the random variables $x_i$ were actually uniformly distributed, not normally distributed, which may have been hard to assess with only $N=10$ samples!*
    \label{fig:ExBootStdDev*
\end{figure* -->
<p>To be extremely explicit, consider the following example where I have <span class="math notranslate nohighlight">\(N=10\)</span> observations</p>
<div class="math notranslate nohighlight">
\[\vec{x} = \left[x_1, x_2, \ldots, x_{10}\right],\]</div>
<p>and I calculate their standard deviation</p>
<div class="math notranslate nohighlight" id="equation-eqn-unbiasedsigma">
<span class="eqno">(19)<a class="headerlink" href="#equation-eqn-unbiasedsigma" title="Permalink to this equation">#</a></span>\[s = \frac{1}{N-1} \sqrt{\sum_{i=1}^N\left(
    x_i-\bar{x}
\right)^2}.\]</div>
<p>(The value above is actually known as the <em>unbiased</em> estimator for the standard deviation, but that is a detail.)  I want to know the confidence interval for <span class="math notranslate nohighlight">\(s\)</span>, but I don’t know theoretically how it’s distributed, so I’m going to use bootstrapping.  (For normally distributed data, <span class="math notranslate nohighlight">\(s\)</span> is distributed according to the aptly named  <a class="reference external" href="https://mathworld.wolfram.com/StandardDeviationDistribution.html">Standard Deviation Distribution</a>.)</p>
<p>To do this, I generate a new list of observations by randomly picking from <span class="math notranslate nohighlight">\(\vec{x*\)</span>.  For example,</p>
<div class="math notranslate nohighlight">
\[\vec{x}^*_1 = \left[x_6, x_3, x_9, x_4, x_4, x_{10}, x_9, x_5, x_9, x_5\right],\]</div>
<p>where I can get multiple of one of my initial values because each time I pick, I pick from the full list.  (As a quick hack, I generated these numbers in Python using <code class="docutils literal notranslate"><span class="pre">newIndices</span> <span class="pre">=</span> <span class="pre">(np.random.rand(10)*10).astype(int)</span> <span class="pre">+</span> <span class="pre">1</span></code>. See if you can make sense of this for your own use, or ask about it in class!)</p>
<p>Using <span class="math notranslate nohighlight">\(\vec{x}_1^*\)</span>, I then use Equation <a class="reference internal" href="#equation-eqn-unbiasedsigma">(19)</a> to calculate a new standard deviation <span class="math notranslate nohighlight">\(s_1^*\)</span>. I then repeat this process <span class="math notranslate nohighlight">\(N_{BOOT}\)</span> times: I generate <span class="math notranslate nohighlight">\(\vec{x}_1^*, \vec{x}_2^*, \ldots, \vec{x}_{N_{BOOT}}^*\)</span> (we can collect these into an <span class="math notranslate nohighlight">\(N_{BOOT}\times N\)</span> array called <span class="math notranslate nohighlight">\(X^*\)</span>).  And I calculate <span class="math notranslate nohighlight">\(s_1^*, s_2^*, \ldots, s_{N_{BOOT}}^*\)</span> and I <em>plot their distribution</em>.  If I’m interested in an <span class="math notranslate nohighlight">\(\alpha=5\%\)</span> confidence level, then I can find the empirical <span class="math notranslate nohighlight">\(2.5^{\text{th}}\)</span> and <span class="math notranslate nohighlight">\(97.5^{\text{th}}\)</span> percentiles and report that 95% of the time, <span class="math notranslate nohighlight">\(\hat{s}\)</span> falls in that region.</p>
<div class="admonition-bootstrapping-confidence-intervals admonition">
<p class="admonition-title">Bootstrapping confidence intervals</p>
<p>Given <span class="math notranslate nohighlight">\(N\)</span> data points <span class="math notranslate nohighlight">\(\vec{x}\)</span>, and a parameter <span class="math notranslate nohighlight">\(\theta(\vec{x})\)</span>, we can generate confidence intervals at a confidence level <span class="math notranslate nohighlight">\(\alpha\)</span> with the following process:</p>
<ul class="simple">
<li><p>Generate <span class="math notranslate nohighlight">\(N_{BOOT}\)</span> resamplings of <span class="math notranslate nohighlight">\(\vec{x}\)</span> with replacement: <span class="math notranslate nohighlight">\(\vec{x}_j^*\)</span>.</p></li>
<li><p>Calculate <span class="math notranslate nohighlight">\(\theta^* = \theta(\vec{x}_j^*)\)</span> for <span class="math notranslate nohighlight">\(j=1,\ldots,N_{BOOT}\)</span>.</p></li>
<li><p>The confidence interval is the <span class="math notranslate nohighlight">\(\alpha/2^{\text{th}}\)</span> and <span class="math notranslate nohighlight">\((1-\alpha/2)^{\text{th}}\)</span> percentiles of the distribution of <span class="math notranslate nohighlight">\(\theta^*\)</span>.</p></li>
</ul>
</div>
<p>Hopefully you can see that this is a relatively easy technique to use, it can be straightforwardly applied to many data sets, and its results are very interpretable, making bootstrapping an immensely useful tool.</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>At this point you should have everything you need to attempt <a class="reference internal" href="Worksheet_2_1_Bootstrapping.html"><span class="doc std std-doc">Worksheet 2.1</span></a>.</p>
<p>Once you’ve completed that, you should be able to start on <a class="reference internal" href="Assignment_2.html"><span class="doc std std-doc">Assignment 2</span></a>, Problem 1.</p>
</div>
</section>
</section>
<section id="the-atom-of-model-fitting-least-squares-regression">
<h2>The atom of model fitting: least-squares regression<a class="headerlink" href="#the-atom-of-model-fitting-least-squares-regression" title="Permalink to this headline">#</a></h2>
<p>At this point, hopefully you can see that we have at least attempted to answer our questions:</p>
<ul>
<li><p>How likely am I to observe this estimate?</p>
<blockquote>
<div><p><em>Answer:</em> I can read off the height of the likelihood, posterior, or empirical bootstrapped distribution at that value to get this answer.</p>
</div></blockquote>
</li>
<li><p>How confident are you in this estimate?</p>
<blockquote>
<div><p><em>Answer:</em> Using a confidence or credible interval, I can describe regions of confidence.</p>
</div></blockquote>
</li>
<li><p>How much deviation from this estimate should I expect?</p>
<blockquote>
<div><p><em>Answer:</em> Confidence intervals give me bounds that overlap the underlying truth <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> of the time.  Credible intervals tell me where <span class="math notranslate nohighlight">\((1-\alpha)\%\)</span> of the probability of observing <span class="math notranslate nohighlight">\(\theta\)</span> is, given my data.</p>
</div></blockquote>
</li>
</ul>
<p>Furthermore, we now have the tools to really get into something interesting: <em>model fitting</em>.</p>
<p>In science, we are generically trying to build <em>relationships</em> between different phenomena.  When I increase the volume of a gas, what happens to its temperature?  If a neuron fires in one location of your brain, do you subsequently kick your leg?  If I place a chemical gradient over some bacteria, which direction do they move?  To do this, we use models, which can be extremely descriptive or very generic.</p>
<p>Why do we use these models?  This is a somewhat deep question that many people have different answers for, but our answer is practical.  The point of having a model is twofold:</p>
<ol class="simple">
<li><p>A good model allows you to <em>extrapolate</em> beyond the regimes spanned by your measurements and to make new <em>predictions</em>.</p></li>
<li><p>A robust model that performs well in a variety of situations might be hinting at an underlying <em>principle</em> that can bring predictive understanding to a broader range of phenomena.
\end{enumerate*
Either of these reasons would be sufficient justification for using modeling as a part of the scientific method, but it is worth noting that both are powerful and useful statements.</p></li>
</ol>
<p>These models usually have <em>parameters</em>, which are quantities that often have some physical significance, and these parameters themselves need to be measured or estimated in order for the model to make sense.
This is the problem of model fitting: I think that I have the correct <em>functional shape</em> for my relationship (my quantities are related linearly, or logarithmically, or some other way), and I want to use my data to estimate the parameters of the model.  In this way, you can see why we first talked about parameter estimation: model fitting is a specific application of this concept!</p>
<section id="ordinary-least-squares-regression">
<h3>Ordinary least-squares regression<a class="headerlink" href="#ordinary-least-squares-regression" title="Permalink to this headline">#</a></h3>
<p>In the following section we will present the method of <em>ordinary least-squares</em> (OLS) linear regression.  This may seem to some readers to be a trivially simple method, but we hope that our discussion serves as a useful guide to ideas that generalize to more advanced methods that you might encounter.  In this way, we’ll be using linear regression as an example on which we can explore the concepts of model-fitting capability, under- and over-fitting, and predictive ability.</p>
<p>There are many ways to go about model fitting, but one of the most robust, famous, useful, and simplest methods is the method of <strong>least-squares regression</strong>.  In the simplest version of this method, we have <span class="math notranslate nohighlight">\(N\)</span> pairs of data points <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> and we want to build a relationship between them.  For this example, call <span class="math notranslate nohighlight">\(x\)</span> the <strong>independent</strong> variable and <span class="math notranslate nohighlight">\(y\)</span> the <strong>dependent</strong> variable; that is, we’re going to model <span class="math notranslate nohighlight">\(y\)</span> as depending on <span class="math notranslate nohighlight">\(x\)</span>.  In the context of regression, we often call <span class="math notranslate nohighlight">\(x\)</span> the <strong>covariates</strong> and <span class="math notranslate nohighlight">\(y\)</span> the <strong>response</strong>.  Let’s then pose the model <span class="math notranslate nohighlight">\(f(\vec{x}, \Theta)\)</span>, where <span class="math notranslate nohighlight">\(\Theta\)</span> are the parameters of the model.  We don’t expect our model to be immediately (or really, ever) perfect, so let’s define the <strong>residual</strong> to be discrepancy between the model and the data:</p>
<div class="math notranslate nohighlight">
\[r_i = y_i - f(\vec{x}_i, \Theta).\]</div>
<p>The method of least-squares then seeks to find the values of the parameters <span class="math notranslate nohighlight">\(\Theta\)</span> that <em>minimize</em> the sum of the squared residuals:</p>
<div class="math notranslate nohighlight">
\[SS = \sum_{i=1}^N(r_i)^2.\]</div>
<p>This may seem somewhat technical, but it can also be observed graphically.  Consider <a class="reference internal" href="#fig-lsqexample"><span class="std std-numref">Fig. 19</span></a>.  In this figure, we have data points <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> and we want to fit a line through this data.  The method of least-squares considers the vertical deviations of the line from each <span class="math notranslate nohighlight">\(y_i\)</span> (the residual) and tries to minimize them.</p>
<figure class="align-default" id="fig-lsqexample">
<img alt="Least-squares fit of a linear model, shown in red.  The data to which the model is fit are shown in blue." src="../../_images/LinReg_SimpleExample_Part1.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 19 </span><span class="caption-text">Least-squares fit of a linear model, shown in red.  The data to which the model is fit are shown in blue.</span><a class="headerlink" href="#fig-lsqexample" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<!-- \begin{figure*[htbp]
\centering
\includegraphics[width=\linewidth]{LinReg_SimpleExample_Part1.pdf*
\caption{Least-squares fit of a linear model, shown in red.  The data to which the model is fit are shown in blue.*
\label{fig:lsqExample*
\end{figure* -->
<p>That is, the method of least-squares suggests that the “best” line through the data is the one that generates the <em>smallest average (squared) residual</em> for any given data point.</p>
<p>It is worth noting that this is not the only way that we could have defined “best.”  We could have used the absolute value of the residuals, we could use a weighted sum of the squared residuals because we want the line to fit certain data points better than others, we could redefine the residual to be a different distance.  There are endless choices, and indeed many of these other choices have been explored by statisticians and scientists.  The thought here is not that you need to always consider the entire spectrum of choices (obviously not, since most people don’t consider anything other than OLS), but just to point out that this is a <em>choice</em> that you as an analyzer can make.  One of the goals of this course overall is that regardless of how you make this choice, you will be able to assess your confidence in the outcome, and based on that you can make different choices.</p>
<p>That being said, there are some good reasons to use this method.  First, the democracy with which the data points are treated is the best way to examine new data set.  That is, I don’t know <em>a priori</em> which data points are more or less important to my model, so I should treat them all the same as in OLS.</p>
<p>There is also a practical reason for using least-squares.  The mathematical and computational algorithm for calculating the best-fit parameters is incredibly straightforward and fast.  Before computers this mattered a lot, and even now, it makes more expensive techniques like bootstrapping and Markov Chain simulation that much more tractable if they can use fast algorithms many times.</p>
<p>The final reason is historical.  Most advanced techniques in model fitting are based on modifications to least-squares.  In order to understand more complex methods, understanding the strengths and weaknesses of ordinary least-squares (OLS) is a prerequisite.</p>
<section id="maximum-likelihood-formulation">
<h4>Maximum-likelihood formulation<a class="headerlink" href="#maximum-likelihood-formulation" title="Permalink to this headline">#</a></h4>
<p>So how then do we actually solve this problem?  In this subsection we’ll outline the math of the OLS solution for <em>linear regression</em>.  Later we’ll talk about non-linear models, but it is instructive to consider the linear case first.</p>
<p>As a reader, you should not worry about following all of the math perfectly, but should try and establish some intuition about the results.</p>
<p>Lets start with the simple scenario where we have data about a single response variable and a single covariate. The classical way is to postulate the following:</p>
<div class="math notranslate nohighlight" id="equation-eqn-linreg">
<span class="eqno">(20)<a class="headerlink" href="#equation-eqn-linreg" title="Permalink to this equation">#</a></span>\[y_i = \beta_0 + \beta_1x_i + \varepsilon_i,
\qquad\qquad\text{where}\qquad\qquad
\varepsilon_i \sim\mathcal{N}(0, \sigma^2).\]</div>
<p>That is, <span class="math notranslate nohighlight">\(y\)</span> depends on <span class="math notranslate nohighlight">\(x\)</span> <em>linearly</em> plus some noise, <span class="math notranslate nohighlight">\(\varepsilon\)</span> that is <em>normally distributed</em> with mean <span class="math notranslate nohighlight">\(=0\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<p>This lets us think about <span class="math notranslate nohighlight">\(y_i\)</span> as a random variable with a mean that depends on <span class="math notranslate nohighlight">\(x_i\)</span> linearly.  Specifically:</p>
<div class="math notranslate nohighlight">
\[y_i \sim \mathcal{N}\left(
    \mu=\beta_0 + \beta_1x_i, \sigma^2
\right),\]</div>
<p>so that we can write the likelihood of observing any given <span class="math notranslate nohighlight">\(y_i\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
P\left(
    y_i \left| x_i, \beta_0, \beta_1, \sigma^2
\right.\right) &amp;= 
\frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left[
    -\frac{\left(
        y_i - (\beta_0 + \beta_1x_i)
    \right)^2}{2\sigma^2}
\right]}\\
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left[
    -\frac{\left(
        y_i - \mu_i
    \right)^2}{2\sigma^2}
\right]}\\
&amp;= \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\left[
    -\frac{\left(
        r_i
    \right)^2}{2\sigma^2}
\right]}
\end{align}\end{split}\]</div>
<p>Assuming then that each <span class="math notranslate nohighlight">\((x_i, y_i)\)</span> pair is independent, the likelihood of observing all of <span class="math notranslate nohighlight">\(\vec{y} = [y_1,y_2,\ldots, y_N]\)</span> can be written as the product of the individual likelihoods.</p>
<div class="math notranslate nohighlight" id="equation-eqn-linreglikelihood">
<span class="eqno">(21)<a class="headerlink" href="#equation-eqn-linreglikelihood" title="Permalink to this equation">#</a></span>\[\begin{split}\begin{align}
    P\left(\vec{y}\left|
        \vec{x}, \beta_0, \beta_1, \sigma^2
    \right.\right) &amp;=
    \prod_{i=1}^NP\left(
        y_i \left| x_i, \beta_0, \beta_1, \sigma^2
    \right.\right) \\
    &amp;= \left(
        2\pi\sigma^2
    \right)^{-N/2}\exp \left[
        -\frac{1}{2\sigma^2}\sum_{i=1}^N \left(
            y_i - (\beta_0 + \beta_1x_i)^2
        \right)
    \right]\\
    &amp;= \left(
        2\pi\sigma^2
    \right)^{-N/2}\exp \left[
        -\frac{1}{2\sigma^2}\sum_{i=1}^N \left(
            r_i
        \right)^2
    \right]
\end{align}\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\frac{\sum_{i=1}^Nr_i^2}{2\sigma^2}\)</span> is always positive, you can see then that maximizing the likelihood is <em>equivalent</em> to minimizing the sum of squared residuals!  We wrote this in the context of a linear model, but it’s worth noting that this is true for any model <span class="math notranslate nohighlight">\(y_i = f(x_i, \beta)\)</span>.</p>
<div class="admonition-ols-maximizes-likelihood admonition">
<p class="admonition-title">OLS maximizes likelihood</p>
<p>The solution to an ordinary least-squares problem is equivalent to finding the maximum likelihood estimator.  (Assuming that the noise is <em>Gaussian distributed</em>.)</p>
</div>
<p>We’ve emphasized this in the text above, but we want to point out that many classical results in probability, statistics, and machine learning are predicated on some of the variables being normally distributed.  While this is not a terrible assumption in the grand scheme of things, it does present difficulties when you aren’t sure that your problem fits these assumptions.  The reason that we don’t stop the text here and tell you to use boilerplate algorithms is because there are <em>other useful ways</em>  to make probabilistic statements about that data without resting on these assumptions.  In any case, for the purposes of concreteness, we’re going to see where the Gaussian approach can take us for a while longer.</p>
<p>Continuing on, just as we did in the section on ML estimation, we can use calculus to find the maximum of Equation <a class="reference internal" href="#equation-eqn-linreglikelihood">(21)</a> with respect to <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span>, our regression coefficients.  Again, don’t worry if you can’t parse the algebra and notation, the takeaway here is that we can turn the crank of ML estimation to get formulas for the <span class="math notranslate nohighlight">\(\beta\)</span> that maximize the likelihood (minimize the sum of squared residuals), given our assumptions about the noise being Gaussian.</p>
<p>In the case of our single covariate linear regression (Equation <a class="reference internal" href="#equation-eqn-linreg">(20)</a>), we can derive the following:</p>
<div class="math notranslate nohighlight">
\[\hat{\beta}_0 = \frac{(\sum y_i)(\sum x_i^2) - (\sum x_i)(\sum x_iy_i)}{N\sum x_i^2 - (\sum x_i)^2*}
\qquad\text{and}\qquad
\hat{\beta}_1 = \frac{N\sum x_iy_i - (\sum x_i)(\sum y_i)}
{N\sum x_i^2 - (\sum x_i)^2},\]</div>
<p>where the <span class="math notranslate nohighlight">\(\sum\)</span> is notation that indicates a sum over terms that iterate <span class="math notranslate nohighlight">\(i=1,\ldots,N\)</span>.  (<span class="math notranslate nohighlight">\(\sum x_i = x_1 + x_2 + \cdots + x_N\)</span>).</p>
<p>This may seem complicated, but we can streamline this using linear algebra and matrix notation to write</p>
<div class="math notranslate nohighlight" id="equation-eqn-linregparamdefns">
<span class="eqno">(22)<a class="headerlink" href="#equation-eqn-linregparamdefns" title="Permalink to this equation">#</a></span>\[\hat{\vec{\beta} = \left(
    X^TX
\right)^{-1} X^T \vec{y},\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\begin{split}\vec{\beta} = \begin{bmatrix}
    \beta_0\\\beta_1
\end{bmatrix},
\qquad\qquad
X = \begin{bmatrix}
    1 &amp; x_1\\
    1 &amp; x_2\\
    \vdots &amp; \vdots \\
    1 &amp; x_N
\end{bmatrix},
\qquad\text{and}\qquad
\vec{y} = \begin{bmatrix}
    y_1\\
    y_2\\
    \vdots\\
    y_N
\end{bmatrix}\end{split}\]</div>
<p>Computers are <em>very good</em> at matrix operations, so this computation is very fast.  Notice also that this notation allows us to generalize to as many covariates as we’d like by adding more columns to <span class="math notranslate nohighlight">\(X\)</span> and more rows to <span class="math notranslate nohighlight">\(\vec{\beta}\)</span>.</p>
<div class="admonition-ols-linear-regression admonition">
<p class="admonition-title">OLS Linear Regression</p>
<p>The solution to the least-squares problem for a linear model can be found with the formula:</p>
<div class="math notranslate nohighlight" id="equation-eqn-linregsoln">
<span class="eqno">(23)<a class="headerlink" href="#equation-eqn-linregsoln" title="Permalink to this equation">#</a></span>\[\hat{\vec{\beta}} = \left(
X^TX
\right)^{-1} X^T \vec{y}\]</div>
</div>
<p>To understand this formula more concretely, consider the example at the end of these notes.</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>At this point, you should be able to attempt <a class="reference internal" href="Worksheet_2_2_OLS_LinReg.html"><span class="doc std std-doc">Worksheet 2.2</span></a>.</p>
<p>Once you’ve finished that, you should be able to start the rest of <a class="reference internal" href="Assignment_2.html"><span class="doc std std-doc">Assignment 2</span></a>.</p>
</div>
</section>
<section id="residual-distributions">
<h4>Residual Distributions<a class="headerlink" href="#residual-distributions" title="Permalink to this headline">#</a></h4>
<p>You may have noticed a potentially large assumption in the previous subsection: the likelihood function depended on the fact that the noise, <span class="math notranslate nohighlight">\(\varepsilon_i\)</span>, was Gaussian-distributed with a <em>constant</em> variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.  It turns out the that the OLS solution in Equation <a class="reference internal" href="#equation-eqn-linregsoln">(23)</a> doesn’t depend on this assumption of Gaussianity, but the interpretation of the estimate as a maximum likelihood estimator, does.  Furthermore, and more importantly, the theoretical derivation of the confidence intervals for our estimates <span class="math notranslate nohighlight">\(\hat{\beta}\)</span> will depend on this assumption.  As you’ll see, this makes a tool such as bootstrapping even more useful, as it will generate confidence intervals regardless of the underlying noise distribution.</p>
<p>Besides assuming that the noise is normally-distributed, the OLS solution also depends on the assumption that the variance in the residuals is <em>constant</em>, which is known as <em>homoscedasticity</em>.  Mathematically, this appears in the fact that the size of the noise, <span class="math notranslate nohighlight">\(\sigma^2\)</span>, in our posing of the problem (Equation <a class="reference internal" href="#equation-eqn-linreg">(20)</a>) is constant and doesn’t depend on <span class="math notranslate nohighlight">\(x_i\)</span> (otherwise we might have said <span class="math notranslate nohighlight">\(\epsilon_i = \mathcal{N}\left(0, \sigma_i^2\right)\)</span>).  But what  this means in real terms is that we’re assuming the noise is the same over the whole range of our measurements.</p>
<p>For example, imagine that you are measuring the relationship between temperature and humidity in the atmosphere and you have one thermometer that is very good when the temperature is above freezing, but doesn’t work otherwise, and you have another thermometer for when it’s below freezing.  Na”ively you would expect that these two devices would have different measurement errors, and even that their measurement errors change as you approach the edge of their measurement range, but if you didn’t indicate this in your analysis, OLS would treat their data as being equivalently errorful.</p>
<p>As a result, it is generically prudent to examine the residual plot, that is, <span class="math notranslate nohighlight">\(r_i\)</span> as a function of <span class="math notranslate nohighlight">\(x_i\)</span> (and sometimes as a function of <span class="math notranslate nohighlight">\(y_i\)</span>!).  Also, you should consider the distribution of <span class="math notranslate nohighlight">\(r_i\)</span> to ensure that it is at least somewhat normally-distributed (although we haven’t yet talked about how to verify this quantitatively). Again OLS doesn’t assume Gaussianity but the MLEs of the <span class="math notranslate nohighlight">\(\beta\)</span>’s do. So if you are using the MLE solution to OLS then checking the assumptions of the two approaches seems wise! It is this philosophy that we wish to convey throughout this course: running modern machine-learning and statistical algorithms on your computers isn’t hard.  What is hard, and rarely done, are directed explorations of whether the approaches are valid and what your confidence in the results is.</p>
<figure class="align-default" id="fig-linregresiddists">
<img alt="Three different ways of examining the residuals of an OLS linear regression fit.  The left panel shows how $r_i$ depends on $x_i$, if there were a  violation of homoscedasticity, it would show up here as a relationship between $r_i$ and $x_i$.  The center plot shows $r_i$ vs $y_i$.  The downward trend in the residuals suggests that the model is overshooting the data when the response is small (large positive residual) and undershooting when the response is large (large negative residual).  The right plot shows the distribution of residuals along side a normal distribution with zero mean and $\sigma = 3$, which is the value that was used to generate the data." src="../../_images/LinReg_SimpleExample_ResidualPlots.jpg" />
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">Three different ways of examining the residuals of an OLS linear regression fit.  The left panel shows how <span class="math notranslate nohighlight">\(r_i\)</span> depends on <span class="math notranslate nohighlight">\(x_i\)</span>, if there were a  violation of homoscedasticity, it would show up here as a relationship between <span class="math notranslate nohighlight">\(r_i\)</span> and <span class="math notranslate nohighlight">\(x_i\)</span>.  The center plot shows <span class="math notranslate nohighlight">\(r_i\)</span> vs <span class="math notranslate nohighlight">\(y_i\)</span>.  The downward trend in the residuals suggests that the model is overshooting the data when the response is small (large positive residual) and undershooting when the response is large (large negative residual).  The right plot shows the distribution of residuals along side a normal distribution with zero mean and <span class="math notranslate nohighlight">\(\sigma = 3\)</span>, which is the value that was used to generate the data.</span><a class="headerlink" href="#fig-linregresiddists" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<!-- \begin{figure*[htbp]
    \centering
    \captionsetup{width=0.8\linewidth*
    \includegraphics[width=\linewidth]{LinReg_SimpleExample_ResidualPlots.pdf*
    \caption{Three different ways of examining the residuals of an OLS linear regression fit.  The left panel shows how $r_i$ depends on $x_i$, if there were a  violation of homoscedasticity, it would show up here as a relationship between $r_i$ and $x_i$.  The center plot shows $r_i$ vs $y_i$.  The downward trend in the residuals suggests that the model is overshooting the data when the response is small (large positive residual) and undershooting when the response is large (large negative residual).  The right plot shows the distribution of residuals along side a normal distribution with zero mean and $\sigma = 3$, which is the value that was used to generate the data.*
    \label{fig:LinRegResidDists*
\end{figure* -->
<p>As an example of such diagnostic plots, consider <a class="reference internal" href="#fig-linregresiddists"><span class="std std-numref">Fig. 20</span></a>.  These plots can be immensely useful in determining whether there are any biases in your fits or any violations of the OLS assumptions.  Also potentially useful is Seaborn’s <code class="docutils literal notranslate"><span class="pre">residplot</span></code>, which plots <span class="math notranslate nohighlight">\(r_i\)</span> vs <span class="math notranslate nohighlight">\(x_i\)</span> with a special kind of smoothing line over the top, as shown <a class="reference external" href="https://seaborn.pydata.org/examples/residplot.html">here</a>.  For now, we leave this recommendation as a qualitative assessment that you can perform after fitting your model, but in the next sections, we’ll establish how you can make this assessment <em>quantitative</em>.  Finally, note that all fitting routines will generate residuals, so you can always make these figures and assess the appropriateness of the fitting assumptions.</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>Using your data and model from Worksheet 2.2, recreate <a class="reference internal" href="#fig-linregresiddists"><span class="std std-numref">Fig. 20</span></a>.  Discuss any patterns that you observe.</p>
</div>
</section>
<section id="maximum-a-posteriori-formulation">
<h4>Maximum <em>a posteriori</em> formulation<a class="headerlink" href="#maximum-a-posteriori-formulation" title="Permalink to this headline">#</a></h4>
<p>We can also pose the problem of estimating <span class="math notranslate nohighlight">\(\beta\)</span> in a Bayesian sense.  This section is more mathematically technical, so again, try and focus on the words and results if you are uneasy about algebra and mathematical notation.</p>
<p>In this formulation of the problem, we will again assume that the response depends linearly on the covariates plus some Gaussian noise so that we can write the likelihood as in equation <a class="reference internal" href="#equation-eqn-linreglikelihood">(21)</a>.  However, now we will explicitly model <span class="math notranslate nohighlight">\(\beta_0\)</span>, <span class="math notranslate nohighlight">\(\beta_1\)</span>, and <span class="math notranslate nohighlight">\(\sigma\)</span> (the parameter that OLS linear regression somewhat ignores) so that we can construct a posterior distribution for <em>each</em> of them.</p>
<p>This can be done several ways, but the algebra can be facilitated by choosing a <a class="reference external" href="https://en.wikipedia.org/wiki/Conjugate_prior"><strong>conjugate prior</strong></a> so that the math is easier to work with.  Also, for ease of notation, we will be using <span class="math notranslate nohighlight">\(\vec{\beta}, X,\)</span> and <span class="math notranslate nohighlight">\(\vec{y}\)</span> as defined in equation <a class="reference internal" href="#equation-eqn-linregparamdefns">(22)</a>.  The likelihood function is a normal distribution for <span class="math notranslate nohighlight">\(\vec{\beta}\)</span>, so a conjugate prior for <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> is also normal, while the likelihood function is a <a class="reference external" href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a> for <span class="math notranslate nohighlight">\(\sigma\)</span>, and so it turns out that an <a class="reference external" href="https://en.wikipedia.org/wiki/Inverse-gamma_distribution">inverse Gamma distribution</a> provides a conjugate prior.</p>
<p>It’s worth noting that you don’t need to do this to construct a posterior - we can choose any prior and make the calculation empirically - but as your problem becomes more complicated, it can help to have algebraic forms for certain things.  In any case, if you want to skip the rest of this derivation and use the result, that’s definitely acceptable, this reference should provide a workflow for how to attack new problems.</p>
<p>We write the priors explicitly as:</p>
<div class="math notranslate nohighlight">
\[P\left(\left.
    \vec{\beta}\right|\sigma
\right) = \mathcal{N}_2\left(\left.
    \vec{\beta} \right|
        \vec{\mu}_{\beta},
        \sigma^2\delta_{\beta}^2\mathbb{I}_2
    \right)\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[P(\sigma) = \mathcal{IG}\left(
    a_{0}, b_{0}
\right).\]</div>
<p>Here, <span class="math notranslate nohighlight">\(\mathcal{N}_P\)</span> is a <a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">multivariate Gaussian distribution</a> with</p>
<div class="math notranslate nohighlight">
\[\begin{split}\vec{\mu}_{\beta} = \begin{bmatrix}
    \mu_{\beta, 1}\\
    \mu_{\beta, 2}\\
    \vdots\\
    \mu_{\beta, P}
\end{bmatrix}
\qquad\qquad\text{and}\qquad\qquad
\Sigma_{\beta} = \sigma^2\delta_{\beta}^2
\begin{bmatrix}
    1 &amp; 0  &amp; \cdots &amp; 0 \\
    0 &amp; 1  &amp; \cdots &amp; 0 \\
    \vdots &amp;  \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp;  \cdots &amp; 1
\end{bmatrix}.\end{split}\]</div>
<p>(<span class="math notranslate nohighlight">\(\mathbb{I}_P\)</span> is the <span class="math notranslate nohighlight">\(P\times P\)</span> <em>identity matrix</em>.  In our case, <span class="math notranslate nohighlight">\(P=2\)</span>.)</p>
<p>Notice then that these priors <em>each</em> introduce new parameters, <span class="math notranslate nohighlight">\(\vec{\mu}_{\beta}\)</span>, <span class="math notranslate nohighlight">\(\delta_{\beta}\)</span>, <span class="math notranslate nohighlight">\(a_{0}\)</span>, and <span class="math notranslate nohighlight">\(b_{0}\)</span>, however, as we know, the effect of priors quickly fades with the addition of data, so the exact values of these parameters isn’t that important.  However, if we <em>do</em> have some information about <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> or <span class="math notranslate nohighlight">\(\sigma\)</span>, this method allows us to incorporate this information <em>by design</em>.</p>
<p>When using the Bayesian linear regression, it is often recommended to use <span class="math notranslate nohighlight">\(\vec{\mu}_{\beta} = \vec{\beta}_{OLS}\)</span>, the result from equation <a class="reference internal" href="#equation-eqn-linregsoln">(23)</a>, and <span class="math notranslate nohighlight">\(\delta_{\beta}\)</span> large (center the prior distribution on the OLS solution but give it a large spread to allow for variation).  Similarly, a flat (uninformed) prior for <span class="math notranslate nohighlight">\(\sigma\)</span> can be set by using <span class="math notranslate nohighlight">\(a_{0} = b_{0} = 0.001\)</span> (or some other small number, verify this yourself!).</p>
<p>It’s also worth noting that we have set the prior for <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> as a <em>conditional distribution</em> on our other parameter <span class="math notranslate nohighlight">\(\sigma\)</span>.  This is intentional, but not necessary in general for other problems, but does give the posterior some nice properties in this case that are not worth discussing here.  You can see that Bayes Theorem is flexible enough to allow this when we write</p>
<div class="math notranslate nohighlight">
\[P\left(\left.
    \vec{\beta}, \sigma
\right| X, \vec{y} \right) \propto
P\left(
    \vec{y} \left|
X, \vec{\beta}, \sigma\right.\right)
P\left(\vec{\beta}, \sigma\right),\]</div>
<p>where <span class="math notranslate nohighlight">\(P\left(\vec{\beta}, \sigma\right)\)</span> is the <em>joint distribution</em> for <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>, and our properties of probability distributions tell us that <span class="math notranslate nohighlight">\(P(A, B) = P(A|B)P(B) = P(B|A)P(A)\)</span> so that we can use <span class="math notranslate nohighlight">\(P\left(\vec{\beta}, \sigma\right) = P\left(\left.\vec{\beta}\right|\sigma\right)P(\sigma)\)</span> as our prior.</p>
<p>Finally then, we can multiply these distributions and normalize to find the joint distribution <span class="math notranslate nohighlight">\(P\left(\vec{\beta}, \sigma\right)\)</span>.  This will initially look like a big mess, but we’re only interested in posteriors for just <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> or just <span class="math notranslate nohighlight">\(\sigma\)</span>, so we can <em>marginalize</em> (sum over <span class="math notranslate nohighlight">\(\sigma\)</span> to get <span class="math notranslate nohighlight">\(P\left(\vec{\beta}|\cdots\right)\)</span> or sum over <span class="math notranslate nohighlight">\(\vec{\beta}\)</span> to get <span class="math notranslate nohighlight">\(P(\sigma|\cdots)\)</span> to get the following:</p>
<div class="math notranslate nohighlight">
\[P\left(\left.
    \vec{\beta}\right|X, \vec{y}, \sigma
\right) = \mathcal{N}_P\left(
    \vec{\eta}_{\beta}, \Delta_{\beta}
\right),\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\Delta_{\beta} = \sigma^2\left(
    X^TX + \delta_{\beta}^{-2}\mathbb{I}_P
\right)^{-1}\qquad\qquad \text{and}\qquad\qquad
\vec{\eta}_{\beta} =
\frac{\Delta_{\beta}}{\sigma^2}\left(
    X^T\vec{y} + \frac{\vec{\mu}_{\beta}}{\delta_{\beta}^2}
\right).\]</div>
<p>The posterior for <span class="math notranslate nohighlight">\(\sigma\)</span> becomes</p>
<div class="math notranslate nohighlight">
\[P\left(\sigma^2\left|
    X, \vec{y},\vec{\beta}
\right.\right) = 
\mathcal{IG}\left(
    a_{\sigma}, b_{\sigma}
\right),\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[a_{\sigma} = \frac{N}{2} + \frac{P}{2} + a_0
\qquad\text{and}\qquad
b_{\sigma} = \frac{1}{2}\left[
    \left(\vec{y} - X\vec{\beta}\right)^T
    \left(\vec{y} - X\vec{\beta}\right) + 
    \frac{1}{\delta_{\beta}^2}
    \left(\vec{\beta} - \vec{\mu}_{\beta}\right)^T
    \left(\vec{\beta} - \vec{\mu}_{\beta}\right)
     + 2b_{0}
\right].\]</div>
<p>We can then find the maxima of these posteriors, or their moments, or their percentiles, etc.  We can also draw samples from these distributions to empirically find moments, credible intervals, etc. if we don’t want to do any more theory!</p>
<p>Finally, it’s worth noting that when <span class="math notranslate nohighlight">\(\delta_{\beta}\)</span> is large, then <span class="math notranslate nohighlight">\(\vec{\eta}_{\beta} \rightarrow (X^TX)^{-1}X^T\vec{y}\)</span>, the OLS solution.  Also, the mean of an inverse gamma distribution is given by <span class="math notranslate nohighlight">\(b/(a-1)\)</span>, so again if <span class="math notranslate nohighlight">\(\delta_{\beta}\)</span> is large and <span class="math notranslate nohighlight">\(a_{0}\)</span> and <span class="math notranslate nohighlight">\(b_{0}\)</span> are small, then the mean becomes</p>
<div class="math notranslate nohighlight">
\[E[\sigma^2] \approx
\frac{\left(\vec{y} - X\vec{\beta}\right)^T
    \left(\vec{y} - X\vec{\beta}\right)}
{N + P} = \hat{\sigma}^2_{OLS},\]</div>
<p>which is the OLS point estimator for the variance.</p>
<p>This work may have seemed very technical, and it was.  We omitted a ton of algebra that can be shared upon request (a later version of these notes will put the details somewhere), but the point remains that we can also solve this problem using a Bayesian framework.  Furthermore, this framework explicitly allows for the incorporation of previous knowledge and directly gives us distributional descriptions of our quantities of interest.  Although we won’t discuss it here, the Bayesian methods can relatively straightforwardly be adapted to account for heteroscedasticity, different models for the noise, or other more complicated variable dependencies.  Given this flexibility, the algebra can seem somewhat worth the effort!</p>
<div class="admonition-try-it-yourself admonition">
<p class="admonition-title">Try It Yourself!</p>
<p>Following the example at the end of the notes, implement Bayesian OLS Linear Regression to your data from <a class="reference internal" href="Worksheet_2_2_OLS_LinReg.html"><span class="doc std std-doc">Worksheet 2.2</span></a>.  How do the distributions for the regression coefficients and noise spread (<span class="math notranslate nohighlight">\(\sigma\)</span>) compare to the values you used to make the data?</p>
</div>
<!--     


\subsection{Confidence Regions for Model Parameters*

We've now discussed how to make point estimates of regression coefficients by maximizing the likelihood of the data and by considering posterior distributions of $\vec{\beta}$, but we haven't finished the estimation until we've generated confidence regions.  

You won't be surprised to see that there are 3 approaches to determining regions of confidence in your estimates: ML estimation, examining posteriors, and bootstrapping. You also won't be surprised to see that ML estimation will involve a lot of formulas and math, often relying on assumptions of homoscedasticity and normality of the residuals. We will present those calculations below. However, as is a theme that repeats itself throughout this course, the bootstrapping approach to producing estimates for parameter bounds is practical, straightforward, and generic. 
% In the case of the ML solution to OLS you can produce parameter estimates in a large number of bootstrapped with replacement samples and report the standard deviation of the resulting parameter distributions.

The Bayesian approach requires no additional work than what you have already done to make the (MAP) estimate! The whole point of the Bayesian approach is that it gives a distributional estimate of parameters, and hence you need only report some statistic or region related to the spread of the parameter in question. 

In this section, we'll just show an example of the different methods.  As discussed earlier, the MLE confidence interval will be a formula that can be derived theoretically, the MAP estimator most naturally receives a credible interval that can be generated from the posterior, and we can bootstrap our OLS estimate to approximate the population distributions for our parameters and get confidence intervals computationally.

That is, we'll explain the details of the MLE confidence interval, but the credible interval and bootstrap confidence intervals can be generated using the methods given earlier.  We'll show more detailed work and code for these methods at the end of the notes.

\subsubsection{MLE*

The formula for the confidence interval for a regression coefficient is
\begin{equation*\label{eqn:LinRegCoeffConfInt*
    \left[
        \hat{\beta}_j \pm t_{\alpha/2, N-2*\hat{s*_{\beta_j*
    \right],
\end{equation*
where 
\[
    \hat{s*_{\beta_j* = \sqrt{
        \frac{1*{N-2*
        \frac{\sum_{i=1*^Nr_i^2*{
        \sum_{i=1*^N(x_{i, j*-\bar{x*_j)^2*
\]
is the standard error in the $j^{\text{th*$ regression coefficient.  $t_{p, \nu*$ is the $p^{\text{th*$ percentile of the Student's $t$ distribution with $\nu$ degrees of freedom (\vrb{scipy.stats.t.ppf(p, nu)*).  This is a result of the fact that regression coefficients (under OLS assumptions) are $t$-distributed, which is probably not obvious to you.  It's worth noting that ML confidence intervals are often written as \texttt{Estimate* $\pm$ \texttt{Percentile*$\times$\texttt{Standard Error*, but you shouldn't assume this form unless you know that you can.  In the case of regression coefficients, the *standard error*, is given by the formula above for $\hat{s*_{\beta_j*$.

More generically, it can be shown that the variance in $\beta_j$ is given by $\Sigma_{j,j*$ (the  $j^{\text{th*$ diagonal element of $\Sigma$, where 
\[
    \Sigma = \sigma^2(X^TX)^{-1*.
\]
This matrix is called the *covariance matrix* for $\vec{\beta}$ and is relatively easy to compute (it's often returned by your linear regression function).  So once you have this matrix, you can take the square root of the $j^{\text{th*$ diagonal to get the standard error in that coefficient.  Then the confidence interval can be found by taking $t_{1-\alpha/2, N-2*$ plus/minus the OLS estimate $\hat{\beta}_j$. 

For a non-linear model, this formula provides an *approximation* to the confidence interval, but without knowing more precisely how our parameters are distributed, we cannot derive more precise intervals generically.  In this case, as stated above, you may want to turn to bootstrapping as it provides an empirical route to estimating the spread in parameter estimates.\\

\begin{TryItBox*
    Take a stab at Worksheet 2.3.  Once that's done, you should now be able to tackle the first three problems of Assignment 2.
\end{TryItBox*


\subsection{Model Fitting vs Prediction*
One goal then of a statistical model is that it performs well on *new data* and not just the data on which it was built.  To this point, everything we've discussed is related to *training* the model -- estimating the model parameters from the data.  Parallel to the process of model fitting, we also want to assess the model's *predictive ability*, in particular, its ability to predict responses on previously unobserved inputs, or *generalization*.

% The central challenge or goal of a statistical model is that it performs well, predicts, new and previously unseen data -- not just those on which the model is trained. Everything we have spoken about thus far is related to training a model -- estimating parameters from data. The ability to perform well on previous unobserved inputs is called generalization. 

As a result of these dual goals, it is often recommended in machine learning texts that you should split your data into two sets: a *testing* set for assessing generalization, and a *training* set for fitting the model (estimating the model parameters).  You might see right away then that there are two errors that we want to monitor: the error in matching the training data and the error in predicting the test data.  We'll refer to these as the training and testing error, respectively.

Obviously, a very good model will have both small training and testing errors, but this is not always realized with actual data.  Instead we can note that the average training error will be smaller than the average testing error, so the performance of a model can be assessed both in its ability to shrink its training error and its ability to reduce the gap between the testing and training error.  

More intuitively, these two errors directly correspond to the problems of *overfitting* and *underfitting*.  Underfitting results when the model is unable to to describe even the training data set.  This often corresponds to a model that doesn't have enough flexibility (or is simply inappropriate) to fit the data.  As an example, think about using a linear function to fit a sinusoid.  Overfitting on the other hand results from data that has incorporated the shape of the training data too much and can't predict new data.  This often corresponds to a model having too much flexibility, so that it is inferring more from the data than may be justified.

% So there are actually 2 errors in play when condition training a model and assessing its ability to generalize. Not surprisingly, they are referred to as test error and training error. The test error is assessed on some fraction of the data that has been put aside as a test set that the model isn't trained on. More later on how to determine how to break one dataset into training and test. We want both these to be low. THe model should be well fit to data, and should be able to predict unseen data. Rather obviously, the training data is greater than or equal to the expected value of the training error. So the factors that determine how well a model will perform are its ability to make the training error small, and to reduce the gap between the training and test error. These two factors correspond to the two central challenges in statistical modeling and machine learning: Underfitting and overfitting. Underfitting is when the model is unable to fit a training data set (think using a linear model to fit quadratic data). Overfitting is when a model it is overtrained on a training dataset, leading to large gaps between training and test errors (think fitting a nth order polynomial model to n data points -- this type of model is over leveraged on the training data and will perform very poorly on new/unseen data). 

In this way, we can control whether a model is likely to over- or under-fit by altering its ``capacity" or ``flexibility".  Defining this quantity formally is difficult, but you can think of it as a model's ability to fit a wide variety of functions.  For example, if we extend our linear model to include a quadratic term:
\[
y = \beta_0 + \beta_1 x + \beta_2 x^2,
\]
it has more capacity than the linear model in Equation \ref{eqn:LinReg*.  We could then use OLS to find $\beta_2$ in addition to the other regression coefficients and fit nonlinear models.  As such, we say that models with low capacity may struggle to fit even the training set, while high capacity models might become too conformed to the training set by assuming it has features that it does not.
% We can control whether a model is likely to overfit or underfit by altering its capacity. Attempting to define capacity formally is problematic. Informally, a model's capacity is its ability to fit a wide variety of functions (think of generalized the linear regression model to include nonlinear terms such as $x_i^2$, $exp(x)$, etc. This would be treated as independent covariates and the identical approach to parameter estimation can be used to now fit nonlinear models to the data. In this way you can impart more capacity to the model by giving it a larger variety of functions to fit to the data. Models with low capacity may struggle to fit to the training set. Models with high capcaity can overfit by memorizing properties of the training set that do not serve them well on the test set.

An appropriate, but useless, statement is that a statistical model will generally perform best when its capacity is appropriate for the true complexity of the task and the amount of training data. This topic of capacity will come back when we address regularization-based approaches to statistical modeling in Module 4.  Surprising as it may seem, these approaches will attempt to modulate model capacity and fit the model in a way that is more consistent with the data.\\

\begin{TryItBox*
Split your data from Worksheet 2.2 into a testing and training set.  Use the training set to fit the linear model and assess the *prediction error*, the discrepancy between the model prediction and the actual test data.  Now swap the roles of the two sets, what can you say about your model's generalizability?
\end{TryItBox*

% But, as a preview, regularization is an approach to being able to modulate model capacity in a manner that is appropriate for the data at hand. Said another way, regularization is a modification of a statistical modeling scheme that attempted to reduce its generalization error (the difference between the test and training error), but not its training error. Currently, this might seem impossible. This is what we discuss in Module 4. 


Let's get back to practicalities.  You have a dataset and you want to train your model and assess its generalizabilty.  If you have enough data, you split it into training and test sets so that you can monitor performance and fitting at the same time.

% Now the rubber hits the road. You have a dataset, and you wish to train your algorithm (say a linear model) and wish to assess its ability to generalize. Ideally, you have lots of data. If you have lots of data then you split the data into a training and test subsets. 

How do you know that you have enough data to do this?  Empirically, we would say that such a data is large enough that we've reached a regime where bootstrapped estimates are insensitive to adding more data.  That is, you could run the tests that you've been doing in the worksheets where you ramp up the number of samples that you include in your estimates.  If your estimates keep changing significantly (whatever that may mean) when you add more data, then you don't have enough data to split into two sets.

% What does lots of data mean? Empirically, you can define this as the dataset being so large that bootstrapped sampling with replacement based error bounds on any parametric estimate stops being sensitive to the size of the data. 

For the sake of argument, let's say that you do have ``enough" data to split into two sets, and if you don't you will just have to proceed with even more caution!  How then, should you split your data?  Ideally, the testing and training sets are drawn from a single common distribution, so you can na\"ively guess that breaking your data along the lines of $x < x_0$ and $x > x_0$ will be dangerous, because there might be real differences in your data between those two sets.  In such a case, not only might your training error be large because you don't have a wide-enough range of data to fit your model, your testing error will also be large because the model will never have seen data from the other region.  Instead, the best we can usually do is to select our sets *randomly* from our full data set.  One way to do this quickly in Python is to use \vrb{np.random.shuffle(np.arange(N))* to generate a shuffled list of *indices*.  Then you can, for example, take the first 10\% of these indices to grab your testing set data.

% How should you split your data? Ideally, the test and training data are samples from a common distribution. By way of example, the following would be a terrible way to split the data into training and test: The data is a single response and covariate $(x,y)$, where the training set includes all data with $x<x_0$ and the test includes all data with $x>x_0$. In this extreme example, the test and training datasets are nonoverlapping and hence not only will the generalization error be large, we also don't believe that this is a good test of generalization! 

While this previous point may have been somewhat obvious, it's a bit less obvious what proportions we should split the data.  If we allocate too much data to the testing set, then we'll get a bad fit, but if we allocate too little, then it won't be clear whether the predictive performance was due to the data in the testing set or the model.  This is especially tricky if we're comparing two methods or models!  How then can we balance this?  The answer is called *cross-validation*, which we'll now describe.\\

% How big should the test set be? And, of particular relevance, how do you deal with the fact that we rarely have ``lots" of data. In that instance, cutting up the data into two subsets seems unwise! That said, too small a test set implies statistical uncertainty around the estimated average test error, making it difficult to claim that algorithm A works better than algorithm B on a given task. Are there alternative to partitioning the data to use all the data to estimate the test error? YES! And, again, the computer is what makes it possible. THe approach is called cross-validation, which we now describe.

\begin{TryItBox*
Modulate the size and characteristics of your testing and training sets.  How do training and testing error change as you modulate the size of the testing set?  What happens if you break your data into two sets by putting a threshold on your covariate so that all the data below the threshold is training data and the data above is testing data?
\end{TryItBox*

\subsubsection{Cross Validation*

As we explained earlier, least-squares is just one of many ways that we could choose to optimize our model's parameters. In least-squares, we decided that minimizing the discrepancy between our data and our model was the most important objective.  This is by far the most common tack taken, but an interesting alternative to minimizing these discrepancies is to ask that our coefficients are those such that the model is most *robust* to new data.  That is, maybe we're less concerned that the model match the current data really well, and instead that it should match new future data well.

Alternately, when the parameter of interest is not a model parameter, but an analysis or algorithmic parameter, this perspective can be useful.  Such parameters are called *hyperparameters* and are common in many machine learning or analysis algorithms.

But how can we perform such a fitting?  We don't have *new* data, we only have the data we've collected!  The most common way around this is to use the technique of *cross-validation*.  This method builds on the concept of testing and training data partitions in such a way that addresses some of our questions from earlier.

% This method says that we should take *part* of our collected data and set it aside, and that we should only perform our calculations and analysis on the remaining data.  This is common in machine learning and is known as creating *testing* and *training* data sets.
% \\
% \begin{tcolorbox*{Testing and Training: *
%     Use the training data to fit our model and the test set to assess our model's accuracy.
% \end{tcolorbox* 

% But how do we choose this testing and training set?
In particular, cross-validation will address the concerns that our test or training sets contain outliers or the data are not evenly distributed between the sets along some covariates by going one step further than simply breaking the data into two sets.  Cross-validation says that we should repeatedly break the data into two sets, each time containing different partitions of the data, and assess the accuracy across these repeated partitions.  (You can think of this as bootstrapping the accuracy assessment!)

There are of course many ways to partition your data, but the most common are called $k$-Fold Cross-Validation and *Leave One Out Cross-Validation* (LOOCV).  In $k$-fold CV, one breaks the data set into $k$ equal sized partitions (folds) and sequentially uses each partition as the test set while using the $k-1$ other partitions as the training set.  Often $k=10$ or $k=5$ is used.  The extreme case when $k=N$, the size of the data set, is LOOCV.  This is because we are using all of the data except one point (leaving one out!) and trying to predict that one point.  There are reasons to use or not use LOOCV, but generally, the biggest concern will be how long it takes for the code to run.

The idea then is that you can use CV to fit a model by performing CV repeatedly as you change model parameters.  So if I am performing regression, I can search the $\beta_0$ and $\beta_1$ space to find where some prediction accuracy (the sum of squared residuals or maximum absolute residual, for example) is maximized.  Alternately, if you have data that you know belong in different groups and are trying to generate a model to predict what group a data point is in, then counting the number of correct predictions can be useful.

We'll discuss cross-validation again later when we talk about model *selection*, not just fitting, but we introduce it here because it is a form of parameter estimation.  It's worth noting that CV does not naturally give intervals of confidence, but you could construct a meaningful range on where you think parameters should be set by considering your accuracy vs. parameter curves.\\

\begin{TryItBox*
Apply 10-fold cross-validation to your data from Worksheet 2.2.  For each fold, use bootstrapping to estimate the regression coefficients (point estimate and confidence interval).  Do these distributions overlap significantly from fold to fold?
\end{TryItBox*



\subsection{Comments on Model Fitting*
Throughout this chapter we have tried to stay as high-level as possible, diving into details only to illustrate useful examples.  However, there are some comments that remain that do not belong in the text above.  These are given here.

\subsubsection{Model Selection is For Later!*
You may have noticed that we did not explore the very interesting question of ``what model should I use?"  This was intentional; model selection is just as difficult and unanswerable as the topics discussed here and we feel it deserves its own thoughts.  You will also see that many of the concepts here will rear their heads in that discussion as well, so this chapter will be good to understand in anticipation of that.

\subsubsection{Many Adjustments; For Later*
When discussing least-squares, we pointed out that the method of minimizing residuals was just one of many ways to fit models, and indeed there are many.  In particular, non-linear models provide their own difficulties, and we'll discuss them shortly.

In the context of regression, there have been many good and powerful adjustments to the basic regression scheme that improve the predictive accuracy of those models and also aid in the development of a *sparse* model - a model that has fewer covariates.  We hope to discuss this later, but if you are interested, the most popular adjustment is known as *regularization*, of which the most popular algorithms are known as *LASSO*, *Ridge Regression*, and a synthesis of the two, *Elastic-Net Regression*.  These names are provided for your reference if you want to investigate them.  These methods are particularly useful when the number of covariates, $P$, becomes close to or larger than the number of observations, $N$, in which case any model will be underdetermined.  Unlike OLS linear regression, these algorithms come with *hyperparameters* that need to be tuned; this is most often done with cross-validation.

\subsubsection{Non-Linear Models*
Finally, as alluded to several times, non-linear models provide OLS with some difficulty.  Not only is the calculus of finding their optima not as well-posed as in the linear case, it's also not clear that we should expect homoscedasticity of the errors, since *by definition* of the model, we expect differently sized changes in response at different values of the covariates.

As a result, the suggestion is that if you have a non-linear model you should attempt to linearize it.  That is, if you want to fit an exponential function, take the logarithm; if you think your model is proportional to a square root of your covariate, then you should fit the squared model with OLS linear regression.  In symbols, it is worse to try and fit
\[
    y = e^{-\beta x*\qquad\qquad\text{and*\qquad\qquad
    y = \sqrt{\alpha x*,
\]
than it is to fit
\[
    \log{y* = -\beta x
    \qquad\qquad\text{and*\qquad\qquad
    y^2 = \alpha x.
\]\\

\begin{TryItBox*
    Create simulated data according to the model
    \[
        y = (x + \varepsilon)^2 + 2(x + \varepsilon) + 1,
    \]
    where you can pick the shape of the noise term $\varepsilon$.  Plot your data.  Try fitting this model using your linear regression methods by supplying covariates $X$ = $[1, x, x^2]$.  Then try fitting the equivalent model
    \[
        \sqrt{y* = (x + \varepsilon) + 1.
    \]
    Examine the regression coefficients and residual distributions.  What do you notice?
\end{TryItBox*

\section{Garcia and Phillips: Real Data!*
For the assignment that accompanies this text, there is a data set, which is a part of the data used in \href{https://northwestern.box.com/s/vza4uqo86xhcsy8wqnzxn5afeoj0rvyn*{this paper* by Garcia and Phillips.  In this paper, Garcia and Phillips generated a *thermodynamic model* of a famous *gene regulatory network*: the network around the **lac* operon*.  This model was exceptional for a few reasons, but among the most interesting applications was that the  model could be used to estimate some quantities that are generally very hard to measure: the actual *number* of certain proteins in a given cell and the *binding energies* of certain proteins to DNA.

To understand why this is interesting and how they made and fit their model, we'll give a little background on gene regulatory networks, the *lac* operon specifically, and thermodynamical models.  Then we'll discuss the data and how they used it in the paper.

\subsection{Biology: Gene Regulatory Networks*
The *Central Dogma of Biology* is a framework for how information is propagated from DNA to proteins.  The general principle is that DNA is *transcribed* into messenger RNA (mRNA), and that RNA is *translated* into proteins.  It's shown as a cartoon in Figure \ref{fig:CentralDogma*.

Of course, reality is not so neat, and there are actually arrows between each of the three components (DNA, RNA, and proteins) in every possible direction.  That is, not only can RNA molecules generate proteins via translation, but they can also interact with DNA to affect transcription.  Similarly, proteins don't just run off to never come back to the nucleus of the cell, they often directly regulate transcription and translation.  As a result, biologists refer to the set of interacting DNA, RNA, and proteins as a *genetic regulatory network* (GRN).  This name more aptly describes the biology in which a *network* of agents *regulate* the expression of one or more *genes*.

\begin{figure*[htbp]
\centering
\includegraphics[width=\linewidth]{CentralDogmaImage_Adjusted.png*
\caption{Illustration of the Central Dogma.  Courtesy of \href{https://www.khanacademy.org/science/high-school-biology/hs-molecular-genetics/hs-rna-and-protein-synthesis/a/intro-to-gene-expression-central-dogma*{Khan Academy*
\label{fig:CentralDogma*
\end{figure*

The *lac* operon GRN refers then to the set of proteins and chemicals that regulate the set of genes known as the *lac* operon.  The *lac* operon, as shown in Figure \ref{fig:LacOperon*,  is a stretch of DNA in *E. coli* that consists of a promoter binding site, an RNA polymerase (RNAP) binding site, a repressor binding site called an *operator*, and three gene coding regions for the genes *lacZ*, *lacY*, and *lacA*.  Based on the growth curves studied by \href{https://northwestern.box.com/s/vza4uqo86xhcsy8wqnzxn5afeoj0rvyn*{Jacob and Monod*, it was noted that *E. coli* bacteria, when placed in an environment with two food sources, glucose and lactose, first consume the glucose, then the lactose.  This suggested that there is some sort of environmental control over when the bacteria would manufacture the enzymes needed for processing lactose.

\begin{figure*[htbp]
\centering
\captionsetup{width=0.8\linewidth*
\includegraphics[width=\linewidth]{Lac_operon.png*
\caption{Diagram of the *lac* operon in each of its four states. Image courtesy of \href{https://en.wikipedia.org/wiki/Lac_operon*{Wikipedia*.*
\label{fig:LacOperon*
\end{figure*

This is indeed the case; the bacteria does not waste energy maintaining or creating enzymes for a food source when there is a much easier to consume resource, glucose, around.  The effect becomes pronounced when only lactose is available, in which case many *lac* genes are expressed, or when there is a lot of glucose and no lactose, in which case almost *no* *lac* genes are transcribed.  

This system has been extensively studied - it is probably one of the best understood regulatory networks we know of.  It has been shown that when lactose is unavailable, a protein, known as a *repressor* binds to the DNA on the operator region, *physically blocking* RNAP, which transcribes the DNA into mRNA, from binding.  Because this protein stops expression, it is called a repressor.  On the other hand, when there is low glucose, another protein, called a *promoter* because it promotes the expression of the gene, binds to the DNA.  This protein, which in this case is named CAP, makes it *easier* for RNAP to bind, thus increasing expression. In this way, the bacteria have direct mechanisms that control *transcription* and not just protein activity as was initially thought.

As a result of the work put into understanding this network as a simple model for all GRNs, this network is often taught in biology courses as an introduction to the topic.  It is likely for a similar reason that Garcia and Phillips chose it to model in their paper.  To understand why they needed a simple network to model, we'll first talk a bit about thermodynamics, whose principles they used to generate their model.

\subsection{Thermodynamics*

At this point it might not surprise you that thinking about things *probabilistically* is a profound and useful way of attacking problems.  Indeed, we'll see that physicists have been using it successfully for centuries, and that it in fact underpins the entire discipline of thermodynamics (and quantum mechanics, but that's not relevant here), which is often called *statistical mechanics*.  Thermodynamics is a branch of physics that attempts to codify the effects of temperature and heat into a set of principles.

One of the base ideas of thermodynamics is that while  physically most things want to have a minimum energy, due to *thermal* fluctuations (random photons hitting atoms, molecules bouncing and jiggling), there is a non-zero likelihood that a system will have some non-minimal energy.  Physicists have then shown that if you can then *enumerate* all the different states in which the system can exist and their energy levels, then you can predict the *probability* that the system will exist in any particular state.

Now, this might sound a bit ridiculous, if I have even a closed box of air, 1 meter to a side, I have on the order of $10^{25*$ molecules in that box, so enumerating all of the different ways that those molecules can be arrayed in my box should seem rather insurmountable.  More concretely, *Boltzmann's distribution* exactly describes the probability of observing any given state as a function of that state:
\begin{equation*
P(\text{state*_i) = \frac{e^{-\frac{E_i*{k_BT*{
\sum_{\text{All States*, j*e^{-\frac{E_j*{k_BT*
 = \frac{e^{-\frac{E_i*{k_BT*{Z*.
\end{equation*
$Z$ is known as the *partition* function, and is the part of the problem that is impossible: sum all the states and their energies.

However, it is often possible to write down the energies and number of ways that a system can be in a few * particular* states, in which case we can talk about the *relative probabilities* of those states by dividing the two Boltzmann distributions so that $Z$ cancels out.  This is often incredibly useful, as Garcia and Phillips note in the development of their model.  We're not often concerned with the probability distribution across all possible states, but just across a few interesting ones.  Known the relative likelihoods in such as situation is very powerful.  In particular, we can see that 
\begin{equation*
\frac{P(\text{state*_i)*{P(\text{state*_j)*
 = \frac{e^{-\frac{E_i*{k_BT*{e^{-\frac{E_j*{k_BT* = e^{-\frac{E_i-E_j*{k_BT*
 = e^{-\frac{\Delta E_{ij*{k_BT*,
\end{equation*
so that the relative probability of observing one state versus another is dependent on the *difference in their energies*.

If we consider our two states to be a molecule, say a protein, binding or not binding to another molecule, say DNA, then the relative likelihood of observing the molecules bound together compared to separate is directly connected to the binding energy of those molecules.  In fact, this is often what we really mean when we talk about binding energies - we want to know the relative likelihood of the molecule being unbound versus bound.

In either case, this binding energy is a useful and interesting quantity to know, but is often difficult to measure directly.  This is especially true in live biological systems, where getting a handle on such chemical measurements is confounded by the thousands of different processes occurring simultaneously.  However, in posing a model that is explicitly based on thermodynamics, Garcia and Phillips were able to make *in vivo* estimates of the binding energy of the *lacI* repressor to DNA.

\subsection{The Experiment and Image Processing*

With this introduction, you are now ready to understand the model and measurements that Garcia and Phillips made.  First, the goal of the paper was twofold: show that a thermodynamic model might describe gene regulation, and then that that model could be used to make estimates of quantities that are normally very hard to measure, like *in vivo* protein numbers.  

This first point is interesting because it's not obvious that gene regulation should be an equilibrium process (as thermodynamics assumes), but it could be that it requires the use of *energy* (via ATP or something similar).  Showing this model's explanatory power was evidence of how the underlying processes work.

Then they used their model to make a variety of predictions, most significantly of the repressor binding energy, $\Delta\varepsilon_{RD*$, and the repressor copy number, $R$.  (The $RD$ stands for *R*epressor-*D*NA to indicate the binding of the repressor to DNA.)  They used other more complicated techniques and results to verify their model fits and found very good agreement.  This suggests that such a model fit and set of experiments might be useful for future measurements of those quantities.

\subsubsection{The Model*
Specifically, the model they fit is given in Equation 5 of their paper:
\begin{equation*
    \text{Fold Change in Expression* = 
    \left(
        1 + \frac{2R*{N_{NS*
        e^{-\beta\Delta\varepsilon_{RD*
    \right)^{-1*,
\end{equation*
where the *Fold Change in Expression* is the change in fluorescence in the presence of repressors compared to when there are no repressors in the system.  $R$ is the number of repressor proteins, $N_{NS* = 5\times10^6$ is the number of *non-specific* binding sites that the repressor could bind on the DNA that wouldn't impact expression, and $\beta = 1/k_BT$ is a Boltzmann factor.

\subsubsection{The Data*
 The data consist of images of *E. coli* bacteria which have been modified so that the existence of certain proteins causes light at different wavelengths to be emitted.  These images are known as *fluorescence* measurements, and are a common type of data in modern biological experiments.  You will have access to several of these images for several mutant strains that are mentioned in the paper.
 
 The images you have been given show the bacteria in three *channels*: a YFP channel, an mCherry channel, and a Phase-Contrast channel.  These first two channels are named after the engineered fluorescent proteins that have been genetically inserted into the bacteria.  The YFP (Yellow Fluorescent Protein) have been engineered to be attached to the *lac* operon, so that when those genes are expressed, the cell will fluoresce yellow.  The mCherry (a red fluorescent protein) has been engineered to be expressed in all bacteria, hopefully enabling the cells to be seen compared to the background.  The Phase-Contrast images are not channels corresponding to specific wavelengths, as in the previous channels, but instead look for *phase shifts* in the light to detect objects with different *optical densities*.  As you can see in the images when you open them, this tends to highlight the *edges* of the bacteria, again potentially allowing us to extract them from the background.
 
 Although this is not known in general, through a complicated calibration experiment, the authors were able to estimate the repressor copy number, $R$ several strains and thus fit the model using fold-change in fluorescence as the response and $R$ as the covariate.

\subsubsection{Image Processing*
In order to get the fluorescence (number of photons) of each bacteria in the images, one must do some *image processing*.  That is, a picture to a computer is just an array of numbers.  Each pixel location has a number telling the relative number of light energy that that part of the detector saw.  The computer does not automatically know where the bacteria are.  Furthermore, while we can look at the images and point to the bacteria, it is not possible to do this consistently when we have a lot of images.  Thus, we must do some work to help the computer automatically find the bacteria in the images.

Specifically, we'll use the mCherry images to find where the *E. coli* are using two techniques called *thresholding* and *erosion and dilation*.  The first method looks at the *distribution* of pixels across the image and tries to find a *threshold* where pixels that have more intensity than the threshold are bacteria and those that have less are not.  This is a somewhat noisy operation, so to smooth out the detected regions, we use the *morphological operations* of erosion and dilation.  These "erode" the detected regions to eliminate small noise, then "dilate" the remaining regions to restore their rough shape.  This is shown in Figure \ref{fig:ImgProcPhase*.  The last panel of this figure is titled "Size-Filtered Image" to indicate that there is also a filter applied that removes detected regions that are too small.

Once we have this last panel in Figure \ref{fig:ImgProcPhase*, we can use it to extract the only the YFP values from the YFP images that correspond to a bacterium and not the background.  It's worth noting that this is only *one method* for performing such processing, and in general the specific pipeline will vary from data set to data set.  However, now that you've seen how this works, it may be worth considering this process when you design your experiment.

As a final note, in the pipeline code that I've given you, the YFP is extracted using processed mCherry images, not the phase-contrast images.  This is purely practical - I found in my own experimentation that the mCherry gave more reliable results.

\begin{figure*[htbp]
    \centering
    \captionsetup{width=0.8\linewidth*
    \includegraphics[width=\linewidth]{ExampleFullPipeline_Phase.pdf*
    \caption{Example of simple image processing pipeline using a phase-contrast image.  The top left panel shows the raw image.  The top right panel shows the distribution of pixels in this image along with an automatically detected threshold.  The middle left panel shows the binary image resulting from applying the threshold to the raw image.  The middle right panel shows the result of applying an erosion operation and the bottom left panel shows the result of a subsequent dilation operation.  The bottom right panel filters the detected regions for size, removing those that are too small; in this case, none were removed.*
    \label{fig:ImgProcPhase*
\end{figure*

\newpage
\section{Review*

So what was the point of this module?  This module was meant to emphasize some of the most fundamental concepts in statistics and science.

% So what was the point of this module? And why should you be reading this? How is this going to help you analyze your data?

% This module conveys some of the most important concepts in statistics and science. 

First, begin quantitative isn't just reporting numbers; being quantitative requires having a fundamental understanding of what the number represents, what assumptions allow that number to be a representation of some part of your data, and how well you even know that number.  We hope that you have started to see how being quantitative involves a deep grappling with uncertainty, and that there are many ways to estimate this uncertainty.

Second, we have introduced the way that you can confront data and models to each other.  While we focused on the nuts and bolts of model fitting, actually doing science involves a back and forth between model generation and model assessment. Furthermore, we have presented model fitting as a specific type of parameter estimation so that the problems posed by model fitting are at the front of your mind when you are fitting your models as well.  Specifically, we want you to ask the same questions when you're calculating a standard deviation that you do when you do linear regression:\\
\begin{NoteBox*{*
\begin{itemize*[noitemsep]
\item How likely am I to observe this estimate?
\item How confident are you in this estimate?
\item How much deviation from this estimate should I expect?
\end{itemize*
\end{NoteBox*
Within answering these questions, you have to assess questions of likelihoods, expectations, and prior knowledge.  We point out that you can leverage your computer to answer these questions more concretely than theory.

% being quantitative doesn't require reporting a number. Being quantitative requires having some fundamental understanding of what the number encapsulates, what the assumption are that go into allows that number to quantitative represent some feature of your data, and providing an estimate for error bars for your quantitative estimate. This is what being quantitative is all about and we hope that this introduction to parameter estimation, point estimates, and intervals of confidence show you that there are several factors to consider, several options that you have to choose from, and quantitative methods to assess the suitability of each approach. 

% Second, is the idea of confronting data and models to each other. While model fitting was the focus of this module it should be stated that often the conversation involves a cycle between model generation, model fitting, assessment of fit and predictive power, back to model generation, .... etc. This is the process of science. We focused on two aspects of the scientific method in this module: Model fitting and an assessment of the fit and the model's predictive power. Model fitting, I hope you see now, is a kind of parameter estimation problem and there are many approaches to doing this. All the issues that rose within the parameter estimation part of the module must be front of mind when doing model fitting as well. What is the basis of this parameter estimation? What is the spread in my estimate consistent with my data? Do I have prior information that would additionally constrain my parameter estimate? But of course there are additional features of modeling fitting, and statistical modeling in general, that go beyond parameter estimation. Is the model appropriate for the data at hand? Are the assumptions made by the model upheld in the data? Perhaps most importantly, how can we assess a model's capacity through its ability to walk the thin line between over and underfitting. Again, as is the theme of this class, instead of using some classical statistics that requires assuming a host of unfounded facts about your data, you can use your computer, in particular cross-validation, to practically produce quantitative estimates of the model fit and predictive power.

Thirdly, we address the aspect of parameter fitting that extends beyond making models purely descriptive, but also *predictive*, by introducing cross-validation.  This aspect of confronting models to data involves assessing the validity of fitting assumptions as well as whether your data are appropriate for the type of model you're considering.  We demonstrate how computational techniques can be used to practically determine your model's tendencies to over- or under-fit.

Finally, we encourage you to take a step back from the details of the module, and see that unlike in Module 1, you are now beginning to use some of the basics to actually analyze data. In particular, we introduced you to important aspects of statistical thinking, problem solving and navigating quantitative problems by giving you exposure to the multiple approaches often used to analyze data, and new methods to calculate and simulate important quantities. 


\subsection{Content Summary*

\begin{itemize*
\item There are many ways to make *point estimates*
\begin{itemize*
    \item *MLE* seeks to maximize the *likelihood* function.
    \item *MAP* seeks to maximimze the *posterior* function.
    \item If you have the distributional form of the posterior, you can also calculate expected values, medians, or modes.
\end{itemize*
\item Point estimates are only so useful, we need to have a region of *confidence*.
\begin{itemize*
    \item *Confidence intervals* measure the confidence to which future experiments will enclose the true parameter.
    \item Confidence intervals require *theoretical* calculations
    \item *Credible intervals* measure the region containing a certain percent of the *probability* of the parameter existing.
    \item Credible intervals represent the *current* probability of $\theta$ having a specific value.
    \item *Bootstrapping* allows for empirical calculation of MLEs and confidence intervals.
\end{itemize*
\item Models have parameters.  These parameters need to be estimated.
\begin{itemize*
    \item *Ordinary Least Squares* (OLS) is a framework that suggests that we should choose the parameters that minimize the sum of the squared residuals, $r_i = y_i - f(\vec{x*_i, \Theta)$.
    \item When we assume the errors are normally distributed, the OLS framework can be posed as a maximum-likelihood problem.
    \item When our model is linear ($y_i = \vec{x*_i\vec{\beta}$), then we can recover the MLE for $\vec{\beta}$ using equation \ref{eqn:LinRegSoln*.  This is known as *linear regression*.
    \item We can also use *Bayesian linear regression* to solve this problem with some relaxed constraints and informed priors.
    \item We can also use bootstrapping to estimate parameters and their confidence intervals.
\end{itemize*
\item *Cross-validation* is a method for systematically assessing the predictive power of your model by breaking your data into *training* and *test* sets.
\begin{itemize*
    \item Cross-validation is often used to fit *hyperparameters*, which are parameters of the algorithm or analysis, not of the model.
    \item $k$-fold cross validation involves breaking the data into $k$ sets and using each of the $k$ partitions, or folds, as the test set in turn.
\end{itemize*
\end{itemize*

\subsection{Learning Goals*

In keeping with the overall learning goal structure of this course, the learning goals of this Module can be broken into the following specific actions.

By the end of the module, it is our goal that a student can...
\begin{itemize*
\item \hlMVD{Manipulating and Visualizing Data*
    \begin{itemize*[noitemsep]
        \item Illustrate estimates and regions of confidence
        \item Illustrate model fits and uncertainty in those fits
        \item Illustrate bootstrapped parameters
        \item Illustrate and annotate plots of model residuals
    \end{itemize*
\item \hlPCS{Performing Calculations and Simulations*
    \begin{itemize*[noitemsep]
        \item Calculate MLEs and confidence intervals using mathematical formulas
        \item Calculate MLEs and confidence intervals using *bootstrapping*
        \item Calculate MAP estimates and credible intervals from computational posterior distributions
        \item Perform OLS linear regression to get estimates of regression coefficients
        \item Calculate estimates and confidence intervals of regression coefficients by combining bootstrapping and linear regression
        \item Use bootstrapped or posterior distributions for parameter to assess the likelihood of deviations from expectation
        \item Calculate the prediction error of a model
        \item Implement cross-validation to calculate the prediction error
        \item Generate estimates of fluorescence from images
    \end{itemize*
    
\item \hlTS{Thinking Statistically*
    \begin{itemize*[noitemsep]
        \item Elaborate on the distributional nature of estimates
        \item Discuss different methods of making estimates and their assumptions
        \item Discuss different methods for making regions of confidence and their assumptions
        \item Determine appropriate methods for estimating different quantities and their uncertainties
        \item Discuss the assumptions and limitations of ordinary least-squares for fitting models
        \item Interpret figures of model residuals to assess model performance
    \end{itemize*
    
\item \hlNQP{Navigating Quantitative Problems*
    \begin{itemize*[noitemsep]
        \item Critique different methods of making estimates and determine an appropriate method for a given data set
        \item Critique different methods of making regions of confidence and determine an appropriate method for a given data set
        \item Determine how and when it is appropriate to explore multiple methods for making estimates
        \item Critique different methods for fitting simple models and determine and appropriate method among them
        \item Assess the predictive ability and appropriateness of a model for a given dataset
        \item Compare models using cross-validation
    \end{itemize*
\end{itemize*

\newpage
\section{Details and Useful Code*

In this section, we will outline some useful details and Python code examples that would have cluttered the main text of the notes.  This section may be a bit more mathematical with less explanation than the rest of the notes, but we will still try and explain the main takeaways without relying on equations or algebra.

\subsection{Derivation of ML Confidence Intervals for Exponential Rate Parameter*

In this subsection we will detail the derivations of the formulas given in Problem 1 of Assignment 2 in which you are asked to calculate the confidence interval for an exponential rate parameter, $\lambda$ in a few different ways.  The work in this subsection is really only for students who are interested in the details and is not at all essential for a complete understanding of this module.  As given in the Assignment, the useful takeaways are the formulas given in Equations \ref{eqn:LConfIntApprox* and \ref{eqn:LConfIntExact*.

In the Assignment problem, you consider two lists of $N = 1372$ time intervals, $\tau_i$, which seem to be exponentially distributed based on their distributions  (see Assignment 1 solutions for an example).  Furthermore, we believe these intervals are exponentially distributed because it is known that the time intervals between Poisson-distributed events are exponentially distributed, and the best first guess at how bacteria run-and-tumble is that the switching is a Poisson process\footnote{See \href{https://doi.org/10.1038/239500a0*{Berg and Brown* (1972) for experimental evidence or \href{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1473391/*{Berg and Purcell* (1977) for a detailed discussion of the "Physics of chemoreception"*.  Based on these assumptions then, we write that the *likelihood* of observing any given $\tau_i$ can be written
\begin{equation*
P\left(\tau_i|\lambda\right) = \lambda e^{-\lambda \tau_i*,
\end{equation*
where $\lambda$ is called the *exponential rate parameter* (it has units of events/time; in this case, $[s^{-1*]$).

The likelihood then of all the $\tau_i$ can be written as
\begin{equation*\label{eqn:ExpLikeAllTau*
P\left(
    \tau_1, \tau_2, \ldots, \tau_N
\right) = \prod_{i=1*^N\lambda e^{-\lambda\tau_i*
 = \lambda^N e^{-\lambda\sum_{i=1*^N\tau_i*.
\end{equation*
We can find the maximum likelihood estimator (MLE), $\hat{\lambda*$ by taking the logarithm of both sides of \ref{eqn:ExpLikeAllTau* and setting the derivative with respect to $\lambda$ to zero.  We also use $\bar{\tau* = \sum\tau_i/N$ to derive:
\begin{align*
\log\left[ P\left(
    \tau_1, \tau_2, \ldots, \tau_N
\right)\right] &= N\log{\lambda* - \lambda N\bar{\tau*\\
\frac{\partial*{\partial\lambda*\left[
\log\left[ P\left(
    \tau_1, \tau_2, \ldots, \tau_N
\right)\right]
\right] &= \frac{N*{\lambda* - N\bar{\tau*\\
\frac{\partial*{\partial\lambda*\left[
    \log[P]
\right] = 0 \qquad &\Rightarrow \qquad \lambda = \frac{1*{\bar{\tau*,
\end{align*
as indicated in the assignment, so that we can use $\hat{\lambda* = 1/\bar{\tau*$ as our MLE for the rate parameter.  However, this doesn't tell us anything about how $\hat{\lambda*$ is distributed, and therefore about our confidence interval for this estimate.  To determine that we'll have to do a little work.\\

\begin{mybox*{MLE of Rate Parameter*
The MLE for the rate parameter of an exponential distribution is given by
\begin{equation*
    \hat{\lambda* = \frac{1*{\sum_{i=1*^N\tau_i*
\end{equation*
\end{mybox*

Our first method proposed in 1.a.i. of the assignment is obviously wrong, but we will make use of its logic to get going on the approximate method given in 1.a.ii \footnote{For more details, consider the post \href{https://stats.stackexchange.com/questions/399809/95-confidence-interval-of-lambda-for-x-1-x-n-iid-exponential-with-rate?newreg=6579dec0b6a54b808a0b9cae6020c137*{here*.*.  In particular, the logic of 1.a.i. says that for a confidence level of $\alpha$, the confidence interval of a normally-distributed quantity, $X$, (like the mean of i.i.d. random variables) is given by [$L$, $U$], where we define $L$ and $U$ as
\begin{equation*
1 - \alpha = P\left(
    L\leq X\leq U
\right) = P\left(
    \mu + z_{\alpha/2*\sigma\leq X\leq \mu+z_{1 - \alpha/2*\sigma
\right),
\end{equation*
where $z_{p*$ is the $p^{\text{th*$ percentile of the standard normal distribution, $\mu$ is the mean of $X$'s distribution, and $\sigma$ is its standard deviation.  We can also write this as
\begin{equation*
1 - \alpha = P\left(
    z_{\alpha/2*\leq \frac{X - \mu}{\sigma} \leq z_{1-\alpha/2*
\right).
\end{equation*
If we were actually considering a mean, $\bar{\tau*$, then the CLT tells us that $\sigma = \sigma_{\tau*/\sqrt{N*$ so that we have
\begin{equation*
1 - \alpha = P\left(
    z_{\alpha/2*\leq \frac{\bar{\tau* - \mu}{\sigma_{\tau*/\sqrt{N* \leq z_{1-\alpha/2*
\right).
\end{equation*
In the case of an exponential distribution, we have $\mu = 1/\lambda$ and $\text{Var*[\tau] = 1/\lambda^2$ so that this equation becomes
\begin{align*
1 - \alpha &= P\left(
    z_{\alpha/2*\leq \sqrt{N*\frac{1/\hat{\lambda* - 1/\lambda*{1/\lambda* \leq z_{1-\alpha/2*
\right)\\
&= P\left(
    \frac{z_{\alpha/2*{\sqrt{N*\leq \frac{\lambda*{\hat{\lambda* -  1\leq \frac{z_{1-\alpha/2*{\sqrt{N*
\right)\\
&= P\left(
    \hat{\lambda*\left(1 + \frac{z_{\alpha/2*{\sqrt{N*\right)\leq \lambda \leq \hat{\lambda*\left(1 + \frac{z_{1-\alpha/2*{\sqrt{N*\right)
\right).
\end{align*
This is the formula given in the assignment.  Of course, this formula rests on the CLT and therefore only applies when $N$ is ``big enough" -- it's approximate.  To make it exact will take a bit more work.  \\

\begin{mybox*{Approximate Confidence Interval for Rate Parameter*
An approximation to the confidence interval for an exponential rate parameter is
\begin{equation*
    \left[ 
        \hat{\lambda*\left(1 + \frac{z_{\alpha/2*{\sqrt{N*\right), \quad \hat{\lambda*\left(1 + \frac{z_{1-\alpha/2*{\sqrt{N*\right)
    \right]\label{eqn:LConfIntApprox*
\end{equation*
\end{mybox*

As noted \href{https://people.missouristate.edu/songfengzheng/Teaching/MTH541/Lecture\%20notes/CI.pdf*{here*, coming up with a formula for the exact confidence interval will require that we make the somewhat odd observation that if a random variable $X$ is exponentially distributed with some rate $\lambda$, then the random variable $Y = 2\lambda X$ is distributed like a $\chi^2$ distribution with 2 degrees of freedom (this is what is noted in problem 1.b.iv.).  More formally, if $X$ is distributed according to $f(x)$ and $y = Y(x)$, then the distribution for $Y$ can be found as
\[
g(y) = f(x(y))\frac{\partial x*{\partial y*.
\]
In our case, $f(x) = \lambda e^{-\lambda x*$, $y(x) = 2\lambda x\Rightarrow x(y) = Y/2\lambda$, and $\frac{\partial x*{\partial y* = 1/2\lambda$.  Putting all this together gives
\[
g(y) = \lambda e^{-\lambda \left(\frac{Y*{2\lambda*\right)*\frac{1*{2\lambda* = \frac{1*{2*e^{-\frac{Y*{2*,
\]
which is the formula for a $\chi^2$ distribution with 2 degrees of freedom (denoted $\chi^2_2$).  

This might have seemed esoteric, but knowing this lets us write the following interval for $Y$ (and therefore $X$):
\begin{equation*
1 - \alpha = P\left(
    \chi_2^2\left(\alpha/2\right)\leq
    Y \leq \chi_2^2\left(1 - \alpha/2\right)
\right),
\end{equation*
where $\chi^2_{\nu*(p)$ is the $p^{\text{th*$ percentile of a $\chi^2$ distribution with $\nu$ degrees of freedom.  We're almost there, now let's set $X = \tau$, our time interval, and note that if each $Y_i\sim\chi^2_2$ then the sum of $Y_i = N\bar{Y*$ is distributed according to $\chi^2_{2N*$ (this is can be shown for $\chi^2$-distributed variables) so that we can re-write the above equation as
\begin{align*
1 - \alpha &= P\left(
    \chi_{2N*^2\left(\alpha/2\right)\leq
    N\bar{Y* \leq \chi_{2N*^2\left(1 - \alpha/2\right)
\right)\\
&= P\left(
    \chi_{2N*^2\left(\alpha/2\right)\leq
    2\lambda N\bar{\tau* \leq \chi_{2N*^2\left(1 - \alpha/2\right)
\right)\\
&= P\left(
    \frac{\chi_{2N*^2\left(\alpha/2\right)*{2N\bar{\tau*\leq \lambda \leq
    \frac{\chi_{2N*^2\left(1-\alpha/2\right)*{2N\bar{\tau*
\right),
\end{align*
which is the formula in the Assignment.\\

\begin{mybox*{(Exact) Confidence Interval for Rate Parameter*
An approximation to the confidence interval for an exponential rate parameter is
\begin{equation*
    \left[
        \frac{\chi_{2N*^2\left(\alpha/2\right)*{2N \bar{\tau*, \quad \frac{\chi_{2N*^2\left(1-\alpha/2\right)*{2N\bar{\tau*
    \right]\label{eqn:LConfIntExact*
\end{equation*
\end{mybox*

As an example of the differences between these assumptions, consider Figure \ref{fig:LambdBoot_2Samp*, where many estimates, $\hat{\lambda*$ were made using $N=5$ and $N=100$ randomly selected samples from our lists of intervals, $\tau^+$ and $\tau^-$.  When $N=5$ there is a significant discrepancy between the normal and $\chi^2$ fits, with the $\chi^2$ fit being much closer to the actual data than the normal distributions.  When we increase the amount of data that goes into the sample to $N=100$, the discrepancy between the $\chi^2$ and normal distributions disappears, so that the fits have essentially the same shape.

\begin{figure*[htbp]
\centering
\captionsetup{width=0.8\linewidth*
\includegraphics[width=\linewidth]{Mod2_Notes_Addendum_LambdaBootstrapped_2SampSizes.pdf*
\caption{Distributions of bootstrapped estimates $\hat{\lambda*$ are shown.  In the top panel, $N=5$ samples are used in each bootstrapped estimate, and $N=100$ are used in the bottom panel.  Fits to normal and $\chi^2$ distributions are shown as dashed and dotted lines, respectively, for each distribution, using the parameterizations described in Equations \ref{eqn:LConfIntApprox* and \ref{eqn:LConfIntExact*.*
\label{fig:LambdBoot_2Samp*
\end{figure*

\subsection{Bayesian Estimation of Mean and Standard Deviation of Normally Distributed R.V.s*

In this subsection we want to provide some code that will demonstrate how we can use Bayes' Theorem to estimate the mean *and standard deviation* of a set of normally distributed random variables.  That is, we'll show the code behind Figures \ref{fig:BayesMAPEst* and \ref{fig:BayesMAPEst2*.

Recall that Bayes' Theorem consists of three important parts:
\begin{equation*
P(PARAM| DATA) \propto P(DATA|PARAM)\times P(PARAM),
\end{equation*
where the left-hand side is the *posterior*, $P(DATA|PARAM)$ is the *likelihood*, and $P(PARAM)$ is the *prior*.  The likelihood function will generally be similar to that used in a ML estimation, and the crucial difference that Bayes' affords us is the application of priors to create an *updating procedure*.  That is, to generate the quantity we want, the posterior, we need to have a prior and likelihood and we need to multiply them together. However, for those of you encountering this formulation for the first time, actually executing this ``multiplication" can be hard to wrap your head around. 
The key to keeping everything in order both in your head and in the code is to recall that your analysis is centered on estimating the *parameter*.  This is different from your normal use of a likelihood function where you consider yourself *given* a parameter value and you input your data to get the numbers.  In this formulation, we consider ourselves *given* the data and we will treat the parameter as our variable input.  

In the code, this means that all of our operations and plots will be *functions of the parameter*.  As a result, I like to recommend that the first step of implementing a Bayesian analysis is to establish a *grid* of parameter values over which your estimation will be performed (over which you'll calculate the prior, likelihood, and posterior distributions).

As an example, let's consider the \href{https://northwestern.box.com/s/30rs60j73xwkwjzhzqqrpi8d2z0l2hu0*{abalones data set* from Assignment 2.  We're going to use the whole weight of the adult abalones as our data and we want to get an estimate for the mean and standard deviation.  Code for loading this data is below:
\begin{py3code*
from collections import Counter
import numpy as np
import pandas as pd
import scipy.stats as st

names = ['Sex', 'Length', 'Diameter', 'Height', 'Whole Weight', 'Shucked Weight',
         'Viscera Weight', 'Shell Weight', 'Rings']

abalones = pd.read_csv("abalones.csv", names=names)

weight = abalones['Whole Weight'][abalones['Sex'] != 'I'].values*200
\end{py3code*
As noted \href{http://archive.ics.uci.edu/ml/datasets/Abalone*{here*, the continuous variables were scaled, so to return to units of grams, we multiply by 200.  Once this has been done, we can determine that there are 2,835 samples in \vrb{weight*, ranging from 3.1g to 565.1g.  Examining the distribution of \vrb{weight*, it seems unlikely that the mean is at the ends of this range, so let's set up a grid for the mean that goes from 100 to 400 grams.  The following code creates a uniformly spaced grid of 1201 points from 100 to 400 (4 grid points per integer).
\begin{py3code*
muGrid = np.linspace(100, 400, 1201)
\end{py3code*

Now that we have the values over which we will be implementing Bayes' Theorem, we need to generate the prior and likelihood distributions.  We'll begin by creating a prior distribution.

First, let's consider a prior distribution for the mean, $\mu$, that doesn't have any knowledge about $\mu$, so it says that all possible values are equally likely (i.e. it is *flat*).  We can calculate this by making a grid of ones the same size as \vrb{muGrid* and normalizing.  Note that normalizing means that the area under the curve is 1, so that if we think of our function as being 1201 rectangles with width $\Delta x = 0.25$, then we need to set the height of those rectangles so that the total area is 1.  In general, if you have a uniformly-spaced grid, you can normalize quickly by dividing by the sum of the $y$-coordinates and then dividing again by $\Delta x$, your grid spacing.
\begin{py3code*
flatPrior = np.ones_like(muGrid)
flatPrior = flatPrior / (np.sum(flatPrior) * np.mean(np.diff(muGrid)))
\end{py3code*
This array now approximates the uniform probability density at each point in \vrb{muGrid*.  To make sure that you have properly normalized, you can check that \vrb{np.sum(flatPrior) * dx* = 1.\\ 

\begin{NoteBox*{Normalization*
*Note:* In other places, we have advocated for normalizing by simply dividing by the $y$-coordinates without considering $\Delta x$.  This is also ok, but is subtly different than the code above as it is not representing probability *density*, but a cumulative probability of being in the bin $[x-\Delta x/2, x + \Delta x/2]$.  Since all computational distributions are discrete, the effect of this is that these quantities differ by the constant factor $\Delta x$ (assuming a uniformly spaced grid), which will be important depending on what calculations you want to do with the arrays.  In particular, if you are calculating moments, you need probabilities and not densities, so \vrb{flatPrior* would need to be multiplied by $\Delta x = 0.25$ for those calculations.
\end{NoteBox*

As a comparison, let's also consider a prior based on a (fictional) study that suggests that here  

\subsection{Conjugate Priors and Post of Exp Rate*

Problem 1 of the assignment with code?

\subsection{Building your own OLS Linear Regression*

Implement the XTXXy formula.

\subsection{Code for Bayesian OLS Linear Regression*

Show what the calculation looks like in Python

\subsection{Error bars on predictions*

Code for different ways of showing error

Show error in *predictions*

\end{document* --></section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./CourseFiles/Module_2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Module_2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Module 2</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Worksheet_2_1_Bootstrapping.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Worksheet 2.1: An introdution to bootstrapping</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Eric Johnson<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>